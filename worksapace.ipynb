{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **navie bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For understnanding Multinomial and Bermouli NavieBayes ,we will take a few sentences and classify them into 2 different classes.\n",
    "\n",
    "each sentence will represent one document. ex: mail,news article , tweet.\n",
    "\n",
    "the analysis and mathmatics involved doesn't depend on the type of document we use.\n",
    "\n",
    "therefore we have chosen a set of small sentences to demonstrate the calculation involved and to drive in the concept.\n",
    "\n",
    "let us first look at the sentences and their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/16. Naive Bayes/1.1 NaiveBayes.zip/NaiveBayes/example_train1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teclov is a great educational institution.</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Educational greatness depends on ethics</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A story of great ethics and educational greatness</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sholey is a great cinema</td>\n",
       "      <td>cinema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good movie depends on good story</td>\n",
       "      <td>cinema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document      Class\n",
       "0         Teclov is a great educational institution.  education\n",
       "1            Educational greatness depends on ethics  education\n",
       "2  A story of great ethics and educational greatness  education\n",
       "3                           Sholey is a great cinema     cinema\n",
       "4                   good movie depends on good story     cinema"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs['Class']= docs.Class.map({'education':1,'cinema':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teclov is a great educational institution.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Educational greatness depends on ethics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A story of great ethics and educational greatness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sholey is a great cinema</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good movie depends on good story</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Class\n",
       "0         Teclov is a great educational institution.      1\n",
       "1            Educational greatness depends on ethics      1\n",
       "2  A story of great ethics and educational greatness      1\n",
       "3                           Sholey is a great cinema      0\n",
       "4                   good movie depends on good story      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "['Teclov is a great educational institution.'\n",
      " 'Educational greatness depends on ethics'\n",
      " 'A story of great ethics and educational greatness'\n",
      " 'Sholey is a great cinema' 'good movie depends on good story']\n",
      "y\n",
      "[1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "numpy_array = docs.as_matrix()\n",
    "x = numpy_array[:,0]\n",
    "y = numpy_array[:,1]\n",
    "y = y.astype('int')\n",
    "print(\"x\")\n",
    "print(x)\n",
    "print('y')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpt_array = docs.as_matrix()\n",
    "x = numpy_array[:,0]\n",
    "y = numpy_array[:,1]\n",
    "y = y.astype('int')\n",
    "print('x')\n",
    "print(x)\n",
    "print(\"y\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine breaking X in individual words and putting them all in a bag. Then we pick all the unique words from the bag one by one and make a dictionary of unique words.\n",
    "\n",
    "This is called vectorization of words. We have the class CountVectorizer() in scikit learn to vectorize the words. Let us first see it in action before explaining it further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an objet of count Vectorizer() class\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here vec is an object of class CountVectorizer()\n",
    "\n",
    "this has an method called fit()\n",
    "\n",
    "which converts a corpus of documents into a vector of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'teclov': 15,\n",
       " 'is': 9,\n",
       " 'great': 6,\n",
       " 'educational': 3,\n",
       " 'institution': 8,\n",
       " 'greatness': 7,\n",
       " 'depends': 2,\n",
       " 'on': 12,\n",
       " 'ethics': 4,\n",
       " 'story': 14,\n",
       " 'of': 11,\n",
       " 'and': 0,\n",
       " 'sholey': 13,\n",
       " 'cinema': 1,\n",
       " 'good': 5,\n",
       " 'movie': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'teclov': 15,\n",
       " 'is': 9,\n",
       " 'great': 6,\n",
       " 'educational': 3,\n",
       " 'institution': 8,\n",
       " 'greatness': 7,\n",
       " 'depends': 2,\n",
       " 'on': 12,\n",
       " 'ethics': 4,\n",
       " 'story': 14,\n",
       " 'of': 11,\n",
       " 'and': 0,\n",
       " 'sholey': 13,\n",
       " 'cinema': 1,\n",
       " 'good': 5,\n",
       " 'movie': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.fit(x)\n",
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'cinema', 'depends', 'educational', 'ethics', 'good', 'great', 'greatness', 'institution', 'is', 'movie', 'of', 'on', 'sholey', 'story', 'teclov']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "print(vec.get_feature_names())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer() has converted the documents into a set of unique words alphabetically sorted and indexed.\n",
    "\n",
    "Stop Words\n",
    "\n",
    "We can see a few trivial words such as 'and','is','of', etc. These words don't really make any difference in classyfying a document. These are called 'stop words'. So we would like to get rid of them.\n",
    "\n",
    "We can remove them by passing a parameter stop_words='english' while instantiating Countvectorizer() as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'teclov': 11,\n",
       " 'great': 5,\n",
       " 'educational': 2,\n",
       " 'institution': 7,\n",
       " 'greatness': 6,\n",
       " 'depends': 1,\n",
       " 'ethics': 3,\n",
       " 'story': 10,\n",
       " 'sholey': 9,\n",
       " 'cinema': 0,\n",
       " 'good': 4,\n",
       " 'movie': 8}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec=CountVectorizer(stop_words = \"english\")\n",
    "vec.fit(x)\n",
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cinema', 'depends', 'educational', 'ethics', 'good', 'great', 'greatness', 'institution', 'movie', 'sholey', 'story', 'teclov']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# printing feature names\n",
    "print(vec.get_feature_names())\n",
    "print(len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our final dictionary is made of 12 words (after discarding the stop words). Now, to do classification, we need to represent all the documents with respect to these words in the form of features.\n",
    "\n",
    "Every document will be converted into a feature vector representing presence of these words in that document. Let's convert each of our training documents in to a feature vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way of representing the features\n",
    "x_transform = vec.transform(x)\n",
    "x_transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see X_tranformed is a 5 x 12 sparse matrix. It has 5 rows for each of our 5 documents and 12 columns each for one word of the dictionary which we just created. Let us print X_transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse matrix  contains a large number of zero-valued elements can both save a significant amount of memory and speed up the processing of that data.\n",
    "* sparse matrix contains the  most of the elements are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 11)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 10)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 9)\t1\n",
      "  (4, 1)\t1\n",
      "  (4, 4)\t2\n",
      "  (4, 8)\t1\n",
      "  (4, 10)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this representation can be understood as follows:\n",
    "\n",
    "Consider first 4 rows of the output: (0,2), (0,5), (0,7) and (0,11). It says that the first document (index 0) has 7th , 2nd , 5th and 11th 'word' present in the document, and that they appear only once in the document- indicated by the right hand column entry.\n",
    "\n",
    "Similarly, consider the entry (4,4) (third from bottom). It says that the fifth document has the fifth word present twice. Indeed, the 5th word('good') appears twice in the 5th document.\n",
    "\n",
    "In real problems, you often work with large documents and vocabularies, and each document contains only a few words in the vocabulary. So it would be a waste of space to store the vocabulary in a typical dataframe, since most entries would be zero. Also, matrix products, additions etc. are much faster with sparse matrices. That's why we use sparse matrices to store the data.\n",
    "\n",
    "Let us convert this sparse matrix into a more easily interpretable array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_transform.toarray()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make better sense of the dataset, let us examine the vocabulary and document-term matrix together in a pandas dataframe. The way to convert a matrix into a dataframe is pd.DataFrame(matrix, columns=columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting matrix into dataframe\n",
    "li = pd.DataFrame(x,columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows how many times a particular word occurs in document. In other words, this is a frequency table of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cinema</th>\n",
       "      <th>depends</th>\n",
       "      <th>educational</th>\n",
       "      <th>ethics</th>\n",
       "      <th>good</th>\n",
       "      <th>great</th>\n",
       "      <th>greatness</th>\n",
       "      <th>institution</th>\n",
       "      <th>movie</th>\n",
       "      <th>sholey</th>\n",
       "      <th>story</th>\n",
       "      <th>teclov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cinema  depends  educational  ethics  good  great  greatness  institution  \\\n",
       "0       0        0            1       0     0      1          0            1   \n",
       "1       0        1            1       1     0      0          1            0   \n",
       "2       0        0            1       1     0      1          1            0   \n",
       "3       1        0            0       0     0      1          0            0   \n",
       "4       0        1            0       0     2      0          0            0   \n",
       "\n",
       "   movie  sholey  story  teclov  \n",
       "0      0       0      0       1  \n",
       "1      0       0      0       0  \n",
       "2      0       0      1       0  \n",
       "3      0       1      0       0  \n",
       "4      1       0      1       0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.\n",
    "\n",
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the \"Bag of Words\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the 4 steps for vectorization are as follows\n",
    "\n",
    "    Import\n",
    "    Instantiate\n",
    "    Fit\n",
    "    Transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us summarise all we have done till now:\n",
    "\n",
    "    vect.fit(train) learns the vocabulary of the training data\n",
    "    vect.transform(train) uses the fitted vocabulary to build a document-term matrix from the training data\n",
    "    vect.transform(test) uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "document=['good at study']\n",
    "Class = ['education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = list(zip(document,Class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(data = z,columns=['document','Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good at study</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        document      Class\n",
       "0  good at study  education"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "df['Class']=df.Class.map({'education':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good at study</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        document Class\n",
       "0  good at study     1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test\n",
      "['good at study']\n",
      "y_test\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_numpy_array = df.as_matrix()\n",
    "x_test = test_numpy_array[:,0]\n",
    "y_test = test_numpy_array[:,1]\n",
    "y_test = y_test.astype('int')\n",
    "print('x_test')\n",
    "print(x_test)\n",
    "print(\"y_test\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_transformed = vec.transform(x_test)\n",
    "x_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test_transformed.toarray()\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTI NOMIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71428571, 0.28571429]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # building a multinomal NB model\n",
    "mnb = MultinomialNB() # instatiate NB class\n",
    "mnb.fit(x,y) # fitting the model on training data\n",
    "mnb.predict_proba(x_test) # predicting the probabilities of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of test document belonging to class CINEMA  [0.71428571]\n",
      "probability of test document belonging to class EDUCATION [0.28571429]\n"
     ]
    }
   ],
   "source": [
    "proba = mnb.predict_proba(x_test)\n",
    "print(\"probability of test document belonging to class CINEMA \" ,proba[:,0])\n",
    "print(\"probability of test document belonging to class EDUCATION\",proba[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cinema</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cinema  Education\n",
       "0  0.714286   0.285714"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(proba,columns=['Cinema',\"Education\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * ** EMAIL SPAM ** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm= pd.read_table('/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/16. Naive Bayes/1.1 NaiveBayes.zip/NaiveBayes/SMSSpamCollection+(1)',header = None,names = ['class','sms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                     sms\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "class    5572 non-null object\n",
      "sms      5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = sm[\"class\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h # ham=0,spam =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting spam and Ham instances\n",
    "# df.column_name.value_counts()-given no.of unique inputs in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham % is  86.59368269921033\n"
     ]
    }
   ],
   "source": [
    "print(\"ham % is \",(h[0]/float(h[0]+h[1]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam % is 13.406317300789663\n"
     ]
    }
   ],
   "source": [
    "print('spam % is',(h[1]/float(h[0]+h[1]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm['label'] = sm[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[\"label\"].loc[sm[\"label\"]==\"spam\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[\"label\"].loc[sm[\"label\"]==\"ham\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                                sms  label\n",
       "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
       "1   ham                      Ok lar... Joking wif u oni...      0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3   ham  U dun say so early hor... U c already then say...      0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.sms\n",
    "y = sm.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state =11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426            I'll be at mu in like  &lt;#&gt;  seconds\n",
       "1247    I do know what u mean,  is the king of not hav...\n",
       "4286                         I pocked you up there before\n",
       "862                              Your brother is a genius\n",
       "3604    I'm not sure, I was just checking out what was...\n",
       "Name: sms, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the sentences  , removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ll': 3927,\n",
       " 'mu': 4368,\n",
       " 'like': 3879,\n",
       " 'lt': 4013,\n",
       " 'gt': 3078,\n",
       " 'seconds': 5630,\n",
       " 'know': 3736,\n",
       " 'mean': 4158,\n",
       " 'king': 3719,\n",
       " 'havin': 3179,\n",
       " 'credit': 1985,\n",
       " 'goin2bed': 2993,\n",
       " 'night': 4503,\n",
       " 'sweet': 6271,\n",
       " 'only1more': 4652,\n",
       " 'sleep': 5856,\n",
       " 'pocked': 4950,\n",
       " 'brother': 1465,\n",
       " 'genius': 2931,\n",
       " 'sure': 6245,\n",
       " 'just': 3654,\n",
       " 'checking': 1683,\n",
       " 'happening': 3148,\n",
       " 'area': 1015,\n",
       " 'sale': 5538,\n",
       " 'arsenal': 1040,\n",
       " 'dartboard': 2073,\n",
       " 'good': 3007,\n",
       " 'condition': 1871,\n",
       " 'doubles': 2301,\n",
       " 'trebles': 6613,\n",
       " 'watever': 6955,\n",
       " 'relation': 5339,\n",
       " 'built': 1492,\n",
       " 'dis': 2225,\n",
       " 'world': 7123,\n",
       " 'thing': 6447,\n",
       " 'remains': 5349,\n",
       " 'atlast': 1076,\n",
       " 'iz': 3557,\n",
       " 'lonlines': 3959,\n",
       " 'lotz': 3983,\n",
       " 'lot': 3978,\n",
       " 'memories': 4190,\n",
       " 'feeling': 2649,\n",
       " 'hotel': 3314,\n",
       " 'dusk': 2366,\n",
       " 'game': 2890,\n",
       " 'think': 6449,\n",
       " 'solve': 5930,\n",
       " 'puzzles': 5182,\n",
       " 'weather': 6976,\n",
       " 'cali': 1538,\n",
       " 'great': 3055,\n",
       " 'complexities': 1859,\n",
       " 'need': 4458,\n",
       " 'car': 1580,\n",
       " 'freely': 2819,\n",
       " 'taxes': 6339,\n",
       " 'outrageous': 4711,\n",
       " 'place': 4900,\n",
       " 'sad': 5528,\n",
       " 'missing': 4256,\n",
       " 'home': 3281,\n",
       " 'kind': 3716,\n",
       " 'took': 6561,\n",
       " 'garage': 2898,\n",
       " 'centre': 1634,\n",
       " 'exhaust': 2549,\n",
       " 'needs': 4461,\n",
       " 'replacing': 5376,\n",
       " 'ordered': 4685,\n",
       " 'taking': 6311,\n",
       " 'fixed': 2718,\n",
       " 'tomo': 6548,\n",
       " 'morning': 4327,\n",
       " 'sleeping': 5858,\n",
       " 'nt': 4565,\n",
       " 'step': 6100,\n",
       " 'outta': 4716,\n",
       " 'way': 6963,\n",
       " 'congrats': 1884,\n",
       " 'frens': 2826,\n",
       " 'lor': 3971,\n",
       " 'wif': 7044,\n",
       " 'mum': 4374,\n",
       " 'sis': 5825,\n",
       " 'bognor': 1356,\n",
       " 'splendid': 6028,\n",
       " 'time': 6498,\n",
       " 'year': 7200,\n",
       " 'hours': 3318,\n",
       " 'went': 7010,\n",
       " 'hair': 3118,\n",
       " 'cut': 2038,\n",
       " '500': 527,\n",
       " 'new': 4487,\n",
       " 'mobiles': 4285,\n",
       " '2004': 347,\n",
       " 'txt': 6669,\n",
       " 'nokia': 4528,\n",
       " '89545': 709,\n",
       " 'collect': 1815,\n",
       " 'today': 6531,\n",
       " 'www': 7162,\n",
       " 'tc': 6346,\n",
       " 'biz': 1312,\n",
       " '2optout': 405,\n",
       " '087187262701': 142,\n",
       " '50gbp': 531,\n",
       " 'mtmsg18': 4365,\n",
       " 'txtauction': 6672,\n",
       " 'ex': 2536,\n",
       " 'wife': 7045,\n",
       " 'able': 754,\n",
       " 'kids': 3708,\n",
       " 'want': 6930,\n",
       " 'day': 2083,\n",
       " 'hey': 3230,\n",
       " 'doc': 2259,\n",
       " 'pls': 4928,\n",
       " 'nice': 4497,\n",
       " 'shirt': 5741,\n",
       " 'hubby': 3340,\n",
       " 'fiting': 2716,\n",
       " 'ones': 4647,\n",
       " 'budget': 1485,\n",
       " 'help': 3216,\n",
       " 'load': 3932,\n",
       " 'card': 1581,\n",
       " 'abi': 750,\n",
       " 'hw': 3365,\n",
       " 'posted': 5005,\n",
       " 'luv': 4026,\n",
       " 'mj': 4266,\n",
       " 'networking': 4481,\n",
       " 'technical': 6363,\n",
       " 'support': 6239,\n",
       " 'associate': 1065,\n",
       " 'thk': 6457,\n",
       " 'gotta': 3027,\n",
       " 'urself': 6780,\n",
       " 'cos': 1934,\n",
       " 'going': 2994,\n",
       " 'shopping': 5759,\n",
       " 'present': 5061,\n",
       " 'decimal': 2104,\n",
       " 'common': 1839,\n",
       " 'better': 1272,\n",
       " 'buy': 1516,\n",
       " 'china': 1715,\n",
       " 'asia': 1050,\n",
       " 'expensive': 2560,\n",
       " 'holla': 3277,\n",
       " 'talking': 6318,\n",
       " 'month': 4318,\n",
       " 'mid': 4217,\n",
       " 'sick': 5792,\n",
       " 'needy': 4462,\n",
       " 'pouts': 5017,\n",
       " 'stomps': 6118,\n",
       " 'feet': 2652,\n",
       " 'slave': 5855,\n",
       " 'urgent': 6771,\n",
       " 'trying': 6638,\n",
       " 'contact': 1899,\n",
       " 'todays': 6532,\n",
       " 'draw': 2317,\n",
       " 'shows': 5778,\n",
       " 'won': 7101,\n",
       " '2000': 345,\n",
       " 'prize': 5088,\n",
       " 'guaranteed': 3082,\n",
       " '09058094507': 174,\n",
       " 'land': 3780,\n",
       " 'line': 3894,\n",
       " 'claim': 1749,\n",
       " '3030': 424,\n",
       " 'valid': 6808,\n",
       " '12hrs': 281,\n",
       " 'collecting': 1817,\n",
       " 'ur': 6767,\n",
       " 'laptop': 3791,\n",
       " 'configure': 1877,\n",
       " 'da': 2048,\n",
       " 'settings': 5687,\n",
       " 'izzit': 3558,\n",
       " 'yar': 7192,\n",
       " 'tot': 6576,\n",
       " 'knew': 3734,\n",
       " 'happen': 3144,\n",
       " 'long': 3957,\n",
       " 'ago': 859,\n",
       " 'blimey': 1327,\n",
       " 'exercise': 2547,\n",
       " 'yeah': 7199,\n",
       " 'kinda': 3717,\n",
       " 'remember': 5350,\n",
       " 'wot': 7132,\n",
       " 'hmm': 3261,\n",
       " 'really': 5277,\n",
       " 'busy': 1511,\n",
       " 'tomorrow': 6550,\n",
       " 'fair': 2599,\n",
       " 'text': 6406,\n",
       " 'banneduk': 1175,\n",
       " '89555': 710,\n",
       " 'cost': 1936,\n",
       " '150p': 297,\n",
       " 'textoperator': 6414,\n",
       " 'g696ga': 2880,\n",
       " '18': 314,\n",
       " 'xxx': 7178,\n",
       " 'best': 1266,\n",
       " 'exam': 2539,\n",
       " 'later': 3801,\n",
       " 'darren': 2072,\n",
       " 'jus': 3653,\n",
       " 'called': 1546,\n",
       " 'ask': 1053,\n",
       " 'wat': 6948,\n",
       " 'wan': 6925,\n",
       " 'started': 6076,\n",
       " 'guessing': 3091,\n",
       " 'finally': 2692,\n",
       " 'guessed': 3089,\n",
       " 'hope': 3296,\n",
       " 'scared': 5588,\n",
       " 'nope': 4538,\n",
       " 'aft': 844,\n",
       " 'bathing': 1201,\n",
       " 'dog': 2271,\n",
       " 'bathe': 1200,\n",
       " 'looks': 3966,\n",
       " 'rain': 5220,\n",
       " 'soon': 5950,\n",
       " 'diff': 2198,\n",
       " 'farm': 2621,\n",
       " 'shop': 5757,\n",
       " 'cheese': 1690,\n",
       " 'little': 3919,\n",
       " 'difficult': 2202,\n",
       " 'simple': 5808,\n",
       " 'enter': 2466,\n",
       " 'sorry': 5959,\n",
       " 'meeting': 4174,\n",
       " 'reckon': 5302,\n",
       " 'town': 6584,\n",
       " 'eightish': 2415,\n",
       " 'walk': 6914,\n",
       " 'carpark': 1600,\n",
       " 'told': 6540,\n",
       " 'tell': 6372,\n",
       " 'stupid': 6171,\n",
       " 'hear': 3194,\n",
       " 'wont': 7107,\n",
       " 'dad': 2050,\n",
       " 'spoken': 6033,\n",
       " 'sim': 5806,\n",
       " 'subscriber': 6185,\n",
       " 'selected': 5648,\n",
       " 'receive': 5292,\n",
       " 'bonus': 1364,\n",
       " 'delivered': 2134,\n",
       " 'door': 2295,\n",
       " 'word': 7114,\n",
       " 'ok': 4628,\n",
       " '88600': 701,\n",
       " 'msg': 4353,\n",
       " 'exp': 2555,\n",
       " '30apr': 425,\n",
       " 'officially': 4618,\n",
       " 'philosophical': 4859,\n",
       " 'hole': 3275,\n",
       " 'wanna': 6928,\n",
       " 'ready': 5268,\n",
       " 'saved': 5577,\n",
       " 'awesome': 1127,\n",
       " 'minute': 4243,\n",
       " 'vodafone': 6872,\n",
       " 'numbers': 4574,\n",
       " 'ending': 2445,\n",
       " '0089': 4,\n",
       " 'digits': 2206,\n",
       " 'received': 5294,\n",
       " '350': 442,\n",
       " 'award': 1124,\n",
       " 'number': 4573,\n",
       " 'matches': 4131,\n",
       " '09063442151': 201,\n",
       " 'love': 3990,\n",
       " 'aathi': 745,\n",
       " 'liao': 3861,\n",
       " 'got': 3023,\n",
       " 'x2': 7164,\n",
       " 'sent': 5669,\n",
       " 'scores': 5600,\n",
       " 'sophas': 5955,\n",
       " 'secondary': 5629,\n",
       " 'application': 991,\n",
       " 'schools': 5594,\n",
       " 'thinking': 6452,\n",
       " 'applying': 994,\n",
       " 'research': 5391,\n",
       " 'joke': 3621,\n",
       " 'ogunrinde': 4623,\n",
       " 'school': 5593,\n",
       " 'oh': 4624,\n",
       " 'clearly': 1767,\n",
       " 'fault': 2632,\n",
       " 'guess': 3088,\n",
       " 'worried': 7124,\n",
       " 'body': 1354,\n",
       " 'repairs': 5371,\n",
       " 'quite': 5201,\n",
       " 'shouldn': 5769,\n",
       " 'worry': 7126,\n",
       " 'slow': 5876,\n",
       " 'tests': 6403,\n",
       " 'guide': 3093,\n",
       " 'ovulation': 4724,\n",
       " 'relax': 5341,\n",
       " 've': 6821,\n",
       " 'said': 5534,\n",
       " 'reason': 5279,\n",
       " 'followin': 2759,\n",
       " 'god': 2987,\n",
       " 'picked': 4876,\n",
       " 'flower': 2744,\n",
       " 'dippeditinadew': 2217,\n",
       " 'lovingly': 4001,\n",
       " 'touched': 6581,\n",
       " 'itwhichturnedinto': 3550,\n",
       " 'gifted': 2954,\n",
       " 'tomeandsaid': 6547,\n",
       " 'friend': 2833,\n",
       " '4u': 521,\n",
       " 'fyi': 2878,\n",
       " 'gonna': 3005,\n",
       " 'sporadically': 6037,\n",
       " 'starting': 6077,\n",
       " 'bc': 1213,\n",
       " 'doin': 2278,\n",
       " 'shit': 5743,\n",
       " '09061743810': 193,\n",
       " 'landline': 3782,\n",
       " 'abta': 762,\n",
       " 'complimentary': 1860,\n",
       " 'tenerife': 6385,\n",
       " 'holiday': 3276,\n",
       " '5000': 528,\n",
       " 'cash': 1607,\n",
       " 'await': 1121,\n",
       " 'collection': 1818,\n",
       " 'sae': 5529,\n",
       " 'cs': 2004,\n",
       " 'box': 1394,\n",
       " '326': 439,\n",
       " 'cw25wx': 2045,\n",
       " '150': 295,\n",
       " 'ppm': 5023,\n",
       " 'dear': 2092,\n",
       " 'voucher': 6880,\n",
       " 'holder': 3273,\n",
       " 'weeks': 6995,\n",
       " 'offer': 4612,\n",
       " 'pc': 4810,\n",
       " 'http': 3338,\n",
       " 'tlp': 6518,\n",
       " 'uk': 6695,\n",
       " 'reward': 5434,\n",
       " 'ts': 6639,\n",
       " 'apply': 992,\n",
       " 'takes': 6309,\n",
       " 'wrc': 7138,\n",
       " 'rally': 5231,\n",
       " 'oz': 4729,\n",
       " 'lucozade': 4020,\n",
       " 'energy': 2452,\n",
       " 'le': 3821,\n",
       " '61200': 569,\n",
       " '25p': 368,\n",
       " 'packs': 4735,\n",
       " 'itcould': 3545,\n",
       " 'senthil': 5671,\n",
       " 'group': 3070,\n",
       " 'company': 1845,\n",
       " 'apnt': 979,\n",
       " '5pm': 557,\n",
       " 'aight': 871,\n",
       " 'fuck': 2854,\n",
       " 'lol': 3951,\n",
       " 'mad': 4059,\n",
       " 'woke': 7097,\n",
       " 'gave': 2911,\n",
       " 'anybody': 965,\n",
       " 'asks': 1058,\n",
       " 'abt': 761,\n",
       " 'tel': 6368,\n",
       " 'wi': 7038,\n",
       " 'nz': 4590,\n",
       " 'players': 4916,\n",
       " 'unsold': 6746,\n",
       " 'boooo': 1374,\n",
       " 'work': 7116,\n",
       " 'quit': 5200,\n",
       " 'swoop': 6284,\n",
       " 'picking': 4877,\n",
       " 'birds': 1299,\n",
       " 'kfc': 3698,\n",
       " 'tuesday': 6650,\n",
       " 'meals': 4157,\n",
       " 'gravy': 3052,\n",
       " 'mark': 4112,\n",
       " 'mobile': 4284,\n",
       " 'content': 1902,\n",
       " 'order': 4684,\n",
       " 'resent': 5393,\n",
       " 'previous': 5073,\n",
       " 'attempt': 1082,\n",
       " 'failed': 2594,\n",
       " 'network': 4480,\n",
       " 'error': 2492,\n",
       " 'queries': 5192,\n",
       " 'customersqueries': 2037,\n",
       " 'netvision': 4479,\n",
       " 'com': 1824,\n",
       " 'costa': 1937,\n",
       " 'del': 2127,\n",
       " 'sol': 5927,\n",
       " '09050090044': 168,\n",
       " 'toclaim': 6530,\n",
       " 'tcs': 6348,\n",
       " 'pobox334': 4943,\n",
       " 'stockport': 6115,\n",
       " 'sk38xh': 5839,\n",
       " '50': 526,\n",
       " 'pm': 4934,\n",
       " 'max10mins': 4146,\n",
       " 'watching': 6952,\n",
       " 'cartoon': 1605,\n",
       " 'listening': 3913,\n",
       " 'music': 4388,\n",
       " 'amp': 924,\n",
       " 'eve': 2512,\n",
       " 'temple': 6382,\n",
       " 'church': 1742,\n",
       " 'driving': 2332,\n",
       " 'reach': 5260,\n",
       " 'destination': 2166,\n",
       " '09095350301': 238,\n",
       " 'send': 5660,\n",
       " 'girls': 2964,\n",
       " 'erotic': 2491,\n",
       " 'ecstacy': 2392,\n",
       " '60p': 567,\n",
       " 'min': 4229,\n",
       " 'stop': 6122,\n",
       " 'texts': 6416,\n",
       " '08712460324': 113,\n",
       " 'nat': 4429,\n",
       " 'rate': 5245,\n",
       " 'say': 5581,\n",
       " 'shun': 5785,\n",
       " 'bian': 1283,\n",
       " 'watch': 6949,\n",
       " 'glass': 2972,\n",
       " 'exhibition': 2551,\n",
       " 'left': 3836,\n",
       " 'vague': 6803,\n",
       " 'inform': 3464,\n",
       " 'person': 4840,\n",
       " 'accounting': 782,\n",
       " 'delayed': 2129,\n",
       " 'rent': 5366,\n",
       " 'discuss': 2236,\n",
       " 'housing': 3323,\n",
       " 'agency': 853,\n",
       " 'renting': 5368,\n",
       " 'online': 4650,\n",
       " 'places': 4903,\n",
       " 'usc': 6782,\n",
       " 'lets': 3855,\n",
       " 'make': 4080,\n",
       " 'saturday': 5572,\n",
       " 'monday': 4307,\n",
       " 'convenience': 1910,\n",
       " 'alright': 906,\n",
       " 'babe': 1142,\n",
       " 'justthought': 3657,\n",
       " 'sayhey': 5582,\n",
       " 'nearly': 4451,\n",
       " 'endof': 2447,\n",
       " 'wk': 7085,\n",
       " 'offdam': 4610,\n",
       " 'nevamind': 4484,\n",
       " '2hook': 391,\n",
       " 'sn': 5908,\n",
       " 'uwant': 6799,\n",
       " 'm8': 4044,\n",
       " 'lovejen': 3992,\n",
       " 'alrite': 907,\n",
       " 'girl': 2961,\n",
       " 'gail': 2882,\n",
       " 'neva': 4483,\n",
       " 'wrong': 7147,\n",
       " 'care': 1585,\n",
       " 'don': 2288,\n",
       " 'l8tr': 3759,\n",
       " 'hun': 3348,\n",
       " 'yaxxx': 7196,\n",
       " 'pass': 4781,\n",
       " '69669': 586,\n",
       " 'polyphonic': 4970,\n",
       " 'ringtones': 5455,\n",
       " 'normal': 4543,\n",
       " 'gprs': 3031,\n",
       " 'charges': 1660,\n",
       " 'enjoy': 2459,\n",
       " 'tones': 6552,\n",
       " 'ar': 1009,\n",
       " 'wanted': 6932,\n",
       " 'short': 5761,\n",
       " 'edge': 2394,\n",
       " 'late': 3798,\n",
       " 'ya': 7187,\n",
       " 'try': 6637,\n",
       " 'money': 4309,\n",
       " 'gary': 2904,\n",
       " 'freak': 2810,\n",
       " 'come': 1829,\n",
       " 'lovin': 3999,\n",
       " 'chance': 1648,\n",
       " 'evaporated': 2511,\n",
       " 'violated': 6852,\n",
       " 'privacy': 5085,\n",
       " 'stealing': 6095,\n",
       " 'phone': 4863,\n",
       " 'employer': 2441,\n",
       " 'paperwork': 4757,\n",
       " 'cool': 1920,\n",
       " 'report': 5382,\n",
       " 'supervisor': 6233,\n",
       " 'pick': 4875,\n",
       " 'oso': 4699,\n",
       " 'sian': 5789,\n",
       " 'tmr': 6523,\n",
       " 'haf': 3113,\n",
       " 'meet': 4172,\n",
       " 'lect': 3833,\n",
       " 'yo': 7222,\n",
       " 'jp': 3638,\n",
       " 'hungry': 3350,\n",
       " 'mofo': 4297,\n",
       " 'people': 4827,\n",
       " 'pay': 4802,\n",
       " 'agree': 860,\n",
       " 'price': 5076,\n",
       " 'willing': 7054,\n",
       " 'marriage': 4117,\n",
       " 'function': 2865,\n",
       " 'did': 2190,\n",
       " 'recently': 5297,\n",
       " 'look': 3961,\n",
       " 'building': 1491,\n",
       " 'coat': 1796,\n",
       " 'hurry': 3356,\n",
       " 'wear': 6972,\n",
       " 'gym': 3104,\n",
       " 'okie': 4632,\n",
       " 'man': 4089,\n",
       " 'shhhhh': 5731,\n",
       " 'supposed': 6241,\n",
       " 'arm': 1028,\n",
       " 'weak': 6968,\n",
       " 'cuz': 2044,\n",
       " 'shot': 5766,\n",
       " 'free': 2814,\n",
       " '1st': 332,\n",
       " 'week': 6990,\n",
       " 'no1': 4521,\n",
       " 'tone': 6551,\n",
       " '8077': 647,\n",
       " 'txting': 6674,\n",
       " 'mates': 4133,\n",
       " 'getzed': 2948,\n",
       " 'pobox': 4938,\n",
       " '36504': 446,\n",
       " 'w45wq': 6894,\n",
       " '16': 309,\n",
       " 'norm150p': 4542,\n",
       " 'wait': 6906,\n",
       " 'till': 6496,\n",
       " 'end': 2443,\n",
       " 'march': 4107,\n",
       " 'el': 2417,\n",
       " 'nino': 4513,\n",
       " 'gets': 2944,\n",
       " 'parked': 4769,\n",
       " 'missionary': 4257,\n",
       " 'hook': 3292,\n",
       " 'doggy': 2275,\n",
       " 'standing': 6068,\n",
       " 'let': 3854,\n",
       " 'details': 2169,\n",
       " 'fri': 2829,\n",
       " 'tom': 6545,\n",
       " 'mentionned': 4197,\n",
       " 'chinese': 1718,\n",
       " 'thanks': 6420,\n",
       " 'murder': 4382,\n",
       " 'exactly': 2538,\n",
       " 'yetunde': 7215,\n",
       " 'class': 1756,\n",
       " 'run': 5513,\n",
       " 'water': 6954,\n",
       " 'balance': 1161,\n",
       " 'question': 5194,\n",
       " 'sang': 5550,\n",
       " 'uptown': 6766,\n",
       " '80': 633,\n",
       " 'answer': 955,\n",
       " '83600': 668,\n",
       " 'luck': 4017,\n",
       " 'siva': 5835,\n",
       " 'hostel': 3311,\n",
       " 'aha': 862,\n",
       " 'hi': 3234,\n",
       " 'lucy': 4021,\n",
       " 'meetins': 4175,\n",
       " 'fancy': 2615,\n",
       " 'cumin': 2023,\n",
       " 'leave': 3830,\n",
       " '2day': 383,\n",
       " '09099726395': 240,\n",
       " 'calls': 1554,\n",
       " 'minmobsmorelkpobox177hp51fl': 4236,\n",
       " 'fine': 2697,\n",
       " 'absolutly': 760,\n",
       " 'somebody': 5933,\n",
       " 'set': 5685,\n",
       " 'website': 6982,\n",
       " 'play': 4913,\n",
       " 'hold': 3272,\n",
       " 'em': 2429,\n",
       " 'using': 6790,\n",
       " 'spacebucks': 5983,\n",
       " 'depends': 2151,\n",
       " 'treated': 6611,\n",
       " 'shoot': 5756,\n",
       " 'docs': 2261,\n",
       " 'waiting': 6909,\n",
       " 'room': 5477,\n",
       " 'membership': 4188,\n",
       " '100': 249,\n",
       " '000': 1,\n",
       " 'jackpot': 3563,\n",
       " '81010': 649,\n",
       " 'dbuk': 2088,\n",
       " 'net': 4474,\n",
       " 'lccltd': 3816,\n",
       " '4403ldnw1a7rw18': 486,\n",
       " '88800': 702,\n",
       " '89034': 705,\n",
       " 'premium': 5053,\n",
       " 'services': 5682,\n",
       " '08718711108': 137,\n",
       " 'dude': 2353,\n",
       " 'ive': 3554,\n",
       " 'seeing': 5641,\n",
       " 'lotta': 3982,\n",
       " 'corvettes': 1933,\n",
       " 'lately': 3799,\n",
       " 'ringtone': 5453,\n",
       " 'club': 1785,\n",
       " 'singles': 5819,\n",
       " 'chart': 1665,\n",
       " 'choose': 1729,\n",
       " 'quality': 5188,\n",
       " 'message': 4205,\n",
       " 'charge': 1658,\n",
       " 'spook': 6034,\n",
       " 'mob': 4282,\n",
       " 'halloween': 3125,\n",
       " 'logo': 3946,\n",
       " 'pic': 4874,\n",
       " 'plus': 4931,\n",
       " 'eerie': 2406,\n",
       " '8007': 637,\n",
       " 'zed': 7248,\n",
       " '08701417012150p': 77,\n",
       " 'ringtoneking': 5454,\n",
       " '84484': 674,\n",
       " 'bit': 1306,\n",
       " 'entry': 2475,\n",
       " 'textpod': 6415,\n",
       " 'win': 7056,\n",
       " '40gb': 475,\n",
       " 'ipod': 3523,\n",
       " '250': 365,\n",
       " 'pod': 4953,\n",
       " '84128': 672,\n",
       " 'custcare': 2032,\n",
       " '08712405020': 111,\n",
       " 'moji': 4298,\n",
       " 'words': 7115,\n",
       " 'rich': 5441,\n",
       " 'bank': 1172,\n",
       " 'granite': 3044,\n",
       " 'issues': 3543,\n",
       " 'strong': 6152,\n",
       " 'explosive': 2569,\n",
       " 'members': 4187,\n",
       " '300': 420,\n",
       " 'nasdaq': 4426,\n",
       " 'symbol': 6289,\n",
       " 'cdgt': 1626,\n",
       " '00': 0,\n",
       " 'ba': 1140,\n",
       " 'gua': 3079,\n",
       " 'mt': 4361,\n",
       " 'faber': 2585,\n",
       " 'yest': 7212,\n",
       " 'mah': 4069,\n",
       " 'read': 5264,\n",
       " 'shame': 5712,\n",
       " 'runs': 5515,\n",
       " 'blame': 1317,\n",
       " 'dreams': 2320,\n",
       " 'winner': 7064,\n",
       " 'valued': 6812,\n",
       " 'customer': 2034,\n",
       " 'hvae': 3364,\n",
       " '900': 720,\n",
       " '09061701444': 189,\n",
       " '24': 361,\n",
       " 'acl03530150pm': 788,\n",
       " 'bad': 1150,\n",
       " 'lady': 3770,\n",
       " 'wats': 6959,\n",
       " 'problem': 5095,\n",
       " 'looking': 3965,\n",
       " 'gone': 3003,\n",
       " '4the': 519,\n",
       " 'test': 6401,\n",
       " 'chosen': 1734,\n",
       " '09066364311': 222,\n",
       " 'information': 3465,\n",
       " 'ikea': 3402,\n",
       " 'spelled': 6009,\n",
       " 'caps': 1577,\n",
       " 'yelling': 7204,\n",
       " 'thought': 6466,\n",
       " 'sitting': 5832,\n",
       " 'bed': 1237,\n",
       " 'mess': 4204,\n",
       " 'came': 1559,\n",
       " 'bullshit': 1495,\n",
       " 'makes': 4081,\n",
       " 'listen': 3910,\n",
       " 'contacted': 1900,\n",
       " 'dating': 2079,\n",
       " 'service': 5681,\n",
       " '09064017305': 209,\n",
       " 'pobox75ldns7': 4947,\n",
       " 'pretty': 5070,\n",
       " 'pussy': 5178,\n",
       " 'dearly': 2095,\n",
       " 'edison': 2395,\n",
       " 'rightly': 5446,\n",
       " 'fool': 2767,\n",
       " 'questions': 5196,\n",
       " 'wise': 7071,\n",
       " 'speechless': 6003,\n",
       " 'viva': 6868,\n",
       " 'gm': 2978,\n",
       " 'gn': 2979,\n",
       " 'ge': 2922,\n",
       " 'gnt': 2981,\n",
       " 'uhhhhrmm': 6692,\n",
       " 'isnt': 3541,\n",
       " 'having': 3180,\n",
       " 'tb': 6344,\n",
       " 'youre': 7229,\n",
       " 'latest': 3802,\n",
       " 'news': 4492,\n",
       " 'police': 4962,\n",
       " 'station': 6085,\n",
       " 'toilet': 6535,\n",
       " 'stolen': 6116,\n",
       " 'cops': 1925,\n",
       " 'rude': 5503,\n",
       " 'campus': 1562,\n",
       " 'project': 5113,\n",
       " 'pa': 4730,\n",
       " 'food': 2766,\n",
       " 'receipt': 5290,\n",
       " 'earlier': 2374,\n",
       " 'created': 1982,\n",
       " 'gap': 2896,\n",
       " 'fingers': 2699,\n",
       " 'comes': 1831,\n",
       " 'fills': 2684,\n",
       " 'gaps': 2897,\n",
       " 'holding': 3274,\n",
       " 'hand': 3129,\n",
       " 'bored': 1379,\n",
       " 'doing': 2279,\n",
       " 'sun': 6220,\n",
       " 'earth': 2379,\n",
       " 'rays': 5252,\n",
       " 'cloud': 1783,\n",
       " 'river': 5461,\n",
       " 'gud': 3084,\n",
       " 'evng': 2528,\n",
       " 'feel': 2647,\n",
       " 'gota': 3024,\n",
       " '0906346330': 203,\n",
       " 'spanish': 5988,\n",
       " '10': 248,\n",
       " '47': 499,\n",
       " 'po19': 4937,\n",
       " '2ez': 386,\n",
       " '150ppm': 301,\n",
       " 'chances': 1649,\n",
       " '20': 343,\n",
       " 'pounds': 5014,\n",
       " 'csh11': 2006,\n",
       " '87575': 695,\n",
       " '6days': 597,\n",
       " 'tsandcs': 6640,\n",
       " 'reply': 5379,\n",
       " 'hl': 3256,\n",
       " 'info': 3463,\n",
       " 'truth': 6636,\n",
       " 'shijutta': 5733,\n",
       " 'successful': 6192,\n",
       " 'right': 5444,\n",
       " 'loads': 3933,\n",
       " 'nasty': 4428,\n",
       " 'cough': 1944,\n",
       " 'dry': 2346,\n",
       " 'yes': 7211,\n",
       " 'reg': 5329,\n",
       " 'ciao': 1743,\n",
       " 'plz': 4933,\n",
       " 'ans': 953,\n",
       " 'bslvyl': 1474,\n",
       " 'fullonsms': 2862,\n",
       " 'ill': 3407,\n",
       " 'drink': 2324,\n",
       " 'srs': 6055,\n",
       " 'model': 4294,\n",
       " 'mail': 4073,\n",
       " 'id': 3384,\n",
       " 'packing': 4734,\n",
       " 'awarded': 1125,\n",
       " '09058094454': 173,\n",
       " 'speed': 6004,\n",
       " 'speedchat': 6005,\n",
       " '80155': 641,\n",
       " 'swap': 6265,\n",
       " 'chatter': 1672,\n",
       " 'chat80155': 1670,\n",
       " 'pobox36504w45wq': 4944,\n",
       " 'rcd': 5254,\n",
       " 'cthen': 2009,\n",
       " 'shd': 5723,\n",
       " 'enuff': 2478,\n",
       " 'conclusion': 1870,\n",
       " 'contents': 1904,\n",
       " 'pg': 4852,\n",
       " 'references': 5320,\n",
       " 'cover': 1960,\n",
       " 'sunday': 6222,\n",
       " 'ew': 2535,\n",
       " 'yetty': 7214,\n",
       " 'grins': 3064,\n",
       " 'hard': 3154,\n",
       " 'believe': 1252,\n",
       " 'things': 6448,\n",
       " 'lie': 3866,\n",
       " 'twice': 6663,\n",
       " 'saying': 5584,\n",
       " 'dont': 2291,\n",
       " 'forget': 2779,\n",
       " 'pix': 4896,\n",
       " 'search': 5623,\n",
       " 'job': 3610,\n",
       " 'superb': 6231,\n",
       " 'grateful': 3048,\n",
       " 'means': 4161,\n",
       " 'opportunity': 4670,\n",
       " 'happier': 3150,\n",
       " 'life': 3868,\n",
       " 'days': 2084,\n",
       " 'happiness': 3152,\n",
       " 'experience': 2561,\n",
       " 'essential': 2502,\n",
       " 'gods': 2988,\n",
       " 'blessings': 1326,\n",
       " 'noe': 4522,\n",
       " 'house': 3319,\n",
       " 'management': 4092,\n",
       " 'puzzeles': 5181,\n",
       " 'guy': 3100,\n",
       " 'used': 6784,\n",
       " 'dumb': 2358,\n",
       " 'realize': 5274,\n",
       " 'account': 781,\n",
       " 'mom': 4302,\n",
       " '3510i': 443,\n",
       " 'colour': 1822,\n",
       " 'deliveredtomorrow': 2135,\n",
       " 'minutes': 4244,\n",
       " 'camcorder': 1558,\n",
       " '08000930705': 50,\n",
       " 'didn': 2191,\n",
       " 'til': 6495,\n",
       " 'nite': 4516,\n",
       " 'unfortunately': 6724,\n",
       " 'pics': 4878,\n",
       " 'obviously': 4598,\n",
       " 'arent': 1017,\n",
       " 'hot': 3313,\n",
       " 'cakes': 1534,\n",
       " 'fun': 2864,\n",
       " 'tho': 6463,\n",
       " 'im': 3411,\n",
       " 'xx': 7175,\n",
       " 'half': 3122,\n",
       " 'years': 7201,\n",
       " 'missed': 4254,\n",
       " 'friendship': 2836,\n",
       " 'aaooooright': 744,\n",
       " 'point': 4956,\n",
       " 'hangin': 3138,\n",
       " 'mr': 4348,\n",
       " 'makin': 4083,\n",
       " 'happy': 3153,\n",
       " 'weekend': 6992,\n",
       " 'kallis': 3668,\n",
       " 'dismissial': 2241,\n",
       " '2nd': 401,\n",
       " 'understanding': 6717,\n",
       " 'sura': 6244,\n",
       " 'responsibilities': 5408,\n",
       " 'dependents': 2150,\n",
       " 'que': 5190,\n",
       " 'pases': 4780,\n",
       " 'buen': 1486,\n",
       " 'tiempo': 6490,\n",
       " 'months': 4320,\n",
       " 'ha': 3108,\n",
       " 'joking': 3625,\n",
       " 'uploaded': 6760,\n",
       " 'facebook': 2587,\n",
       " 'forgot': 2783,\n",
       " 'okay': 4629,\n",
       " 'thanx': 6424,\n",
       " 'gep': 2938,\n",
       " 'bus': 1506,\n",
       " 'finished': 2702,\n",
       " 'ish': 3536,\n",
       " 'fall': 2605,\n",
       " 'actually': 801,\n",
       " 'prone': 5126,\n",
       " 'falls': 2608,\n",
       " 'lucky': 4019,\n",
       " 'fetch': 2658,\n",
       " 'heard': 3195,\n",
       " 'u4': 6686,\n",
       " 'knickers': 3735,\n",
       " 'beg': 1245,\n",
       " '01223585236': 6,\n",
       " 'nikiyu4': 4509,\n",
       " 'mrng': 4350,\n",
       " 'hav': 3173,\n",
       " 'bless': 1324,\n",
       " 'pray': 5040,\n",
       " 'uworld': 6800,\n",
       " 'site': 5828,\n",
       " 'buying': 1519,\n",
       " 'qbank': 5185,\n",
       " 'self': 5650,\n",
       " 'assessment': 1063,\n",
       " 'understood': 6718,\n",
       " 'acted': 792,\n",
       " 'hmmm': 3262,\n",
       " 'board': 1351,\n",
       " 'working': 7120,\n",
       " 'issue': 3542,\n",
       " 'overheating': 4722,\n",
       " 'reslove': 5399,\n",
       " 'software': 5924,\n",
       " 'inst': 3485,\n",
       " 'pending': 4824,\n",
       " 'clock': 1773,\n",
       " 'lar': 3792,\n",
       " 'early': 2376,\n",
       " ...}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000pes', '008704050406', '0089', '0121', '01223585236', '01223585334', '02', '0207', '02072069400', '02073162414', '02085076972', '021', '03', '04', '0430', '05', '050703', '0578', '06', '07', '07008009200', '07090201529', '07099833605', '07123456789', '0721072', '07734396839', '07742676969', '07753741225', '0776xxxxxxx', '07781482378', '07786200117', '07801543489', '07808', '07808247860', '07815296484', '07821230901', '078498', '07880867867', '0789xxxxxxx', '07946746291', '0796xxxxxx', '07973788240', '07xxxxxxxxx', '08', '0800', '08000407165', '08000776320', '08000839402', '08000930705', '08001950382', '08002888812', '08002986030', '08002986906', '08002988890', '08006344447', '0808', '08081263000', '08081560665', '0825', '083', '0844', '08448350055', '08448714184', '0845', '08450542832', '08452810071', '08452810073', '08452810075over18', '0870', '08700435505150p', '08700469649', '08700621170150p', '08701213186', '08701237397', '08701417012', '08701417012150p', '0870141701216', '087016248', '08701752560', '0870241182716', '08702490080', '08702840625', '08704050406', '08704439680', '08704439680ts', '0870737910216yrs', '08707500020', '08707509020', '0870753331018', '08707808226', '08708034412', '08708800282', '08709222922', '08709501522', '0871', '087104711148', '08712101358', '08712103738', '0871212025016', '08712300220', '08712317606', '08712400200', '08712400602450p', '08712400603', '08712402050', '08712402578', '08712402779', '08712402902', '08712402972', '08712405020', '08712405022', '08712460324', '08712466669', '0871277810710p', '0871277810810', '08714342399', '08714712379', '08714712394', '08714712412', '08714714011', '08715203028', '08715203649', '08715203652', '08715203656', '08715203677', '08715203694', '08715205273', '08715500022', '08715705022', '08717111821', '08717168528', '0871750', '08717507382', '08717509990', '08717898035', '08718711108', '08718720201', '08718723815', '08718725756', '08718726270', '087187262701', '08718726978', '087187272008', '08718727868', '08718727870', '08718730666', '08718738001', '08718738002', '08718738034', '08719180219', '08719180248', '08719181513', '08719899217', '08719899229', '08719899230', '09', '09050000301', '09050000332', '09050000460', '09050000555', '09050000878', '09050000928', '09050001295', '09050001808', '09050002311', '09050003091', '09050090044', '09050280520', '09053750005', '09056242159', '09057039994', '09058094454', '09058094507', '09058094565', '09058094583', '09058094594', '09058094597', '09058094599', '09058095201', '09058097189', '09058099801', '09061104276', '09061104283', '09061209465', '09061213237', '09061221061', '09061221066', '09061701444', '09061701461', '09061743386', '09061743806', '09061743810', '09061743811', '09061744553', '09061749602', '09061790121', '09061790125', '09061790126', '09063440451', '09063442151', '09063458130', '0906346330', '09064011000', '09064012103', '09064012160', '09064015307', '09064017295', '09064017305', '09064019014', '09064019788', '09065069120', '09065069154', '09065171142', '09065174042', '09065989182', '09066350750', '09066358152', '09066358361', '09066362220', '09066362231', '09066364311', '09066368327', '09066368470', '09066368753', '09066380611', '09066382422', '09066612661', '09066660100', '09071512432', '09071512433', '09071517866', '09077818151', '09090900040', '09094100151', '09094646631', '09094646899', '09095350301', '09096102316', '09099726395', '09099726429', '09099726553', '09111030116', '09111032124', '09701213186', '0a', '0quit', '10', '100', '1000', '1000call', '1000s', '100p', '100percent', '1013', '1030', '10am', '10k', '10p', '10ppm', '10th', '11', '1120', '113', '1131', '114', '1146', '116', '1172', '118p', '11mths', '11pm', '12', '1205', '120p', '121', '123', '1250', '125gift', '128', '12hrs', '13', '130', '1327', '139', '14', '140', '1405', '140ppm', '145', '1450', '14tcr', '14thmarch', '15', '150', '1500', '150p', '150p16', '150pm', '150ppermesssubscription', '150ppm', '150ppmpobox10183bhamb64xe', '150ppmsg', '150pw', '151', '153', '15541', '15pm', '16', '165', '1680', '169', '177', '18', '180', '1843', '18p', '18yrs', '195', '1956669', '1apple', '1b6a5ecef91ff9', '1cup', '1da', '1er', '1hr', '1im', '1lemon', '1mega', '1million', '1pm', '1st', '1st4terms', '1stchoice', '1stone', '1thing', '1tulsi', '1win150ppmx3', '1winaweek', '1winawk', '1x150p', '1yf', '20', '200', '2000', '2003', '2004', '2005', '2006', '2007', '200p', '2025050', '20m12aq', '20p', '21', '21870000', '21st', '22', '220', '2309', '24', '24hrs', '24m', '25', '250', '250k', '255', '25p', '26', '2667', '26th', '27', '28', '2814032', '28days', '28th', '28thfeb', '29', '2b', '2bold', '2c', '2channel', '2day', '2end', '2exit', '2ez', '2find', '2geva', '2go', '2gthr', '2hook', '2hrs', '2lands', '2marrow', '2moro', '2morow', '2morro', '2morrow', '2mrw', '2mwen', '2nd', '2nhite', '2nights', '2nite', '2optout', '2p', '2px', '2rcv', '2stop', '2stoptx', '2stoptxt', '2u', '2wks', '2wt', '2wu', '2years', '2yr', '2yrs', '30', '300', '300603', '300603t', '300p', '3030', '30apr', '30ish', '30pm', '30pp', '30s', '30th', '31', '3100', '310303', '31p', '32', '32000', '3230', '32323', '326', '33', '330', '350', '3510i', '35p', '3650', '36504', '3680', '373', '3750', '37819', '38', '382', '391784', '3aj', '3d', '3days', '3g', '3gbp', '3lions', '3lp', '3mins', '3mobile', '3optical', '3qxj9', '3rd', '3ss', '3uz', '3x', '3xx', '40', '400', '4041', '40411', '40533', '40gb', '40mph', '41685', '41782', '420', '42049', '4217', '42478', '42810', '434', '440', '4403ldnw1a7rw18', '44345', '447797706009', '447801259231', '449050000301', '449071512431', '45', '450', '450p', '450ppw', '450pw', '45239', '45pm', '47', '4719', '4742', '48', '4882', '48922', '49557', '4a', '4brekkie', '4d', '4few', '4fil', '4get', '4give', '4got', '4info', '4msgs', '4qf2', '4t', '4th', '4the', '4txt', '4u', '4utxt', '4w', '4wrd', '4years', '50', '500', '5000', '505060', '50ea', '50gbp', '50p', '50perweeksub', '50perwksub', '50pm', '50pmmorefrommobile2bremoved', '50ppm', '50rcvd', '50s', '515', '5226', '523', '5249', '526', '528', '530', '54', '542', '545', '5digital', '5free', '5ish', '5k', '5min', '5mls', '5p', '5pm', '5th', '5wb', '5we', '5wkg', '5wq', '5years', '600', '6031', '6089', '60p', '61', '61200', '61610', '6230', '62468', '62735', '630', '63miles', '645', '65', '650', '66', '6669', '674', '67441233', '68866', '69101', '69200', '69669', '69696', '69698', '69855', '69866', '69876', '69888', '69888nyt', '69911', '69969', '69988', '6days', '6hl', '6hrs', '6ish', '6missed', '6months', '6ph', '6pm', '6th', '6zf', '700', '71', '7250', '7250i', '730', '731', '74355', '75', '750', '7548', '75max', '762', '77', '78', '786', '7876150ppm', '79', '7am', '7cfca1a', '7ish', '7mp', '7oz', '7pm', '7th', '7ws', '7zs', '80', '800', '8000930705', '80062', '8007', '80082', '80086', '80122300p', '80155', '80160', '80182', '8027', '80488', '80608', '8077', '80878', '81010', '81151', '81303', '81618', '82050', '820554ad0a1705572711', '82242', '82277', '82468', '83021', '83039', '83049', '83118', '83222', '83332', '83338', '83355', '83370', '83383', '83600', '84', '84025', '84122', '84128', '84199', '84484', '85', '850', '85023', '85069', '85222', '85233', '8552', '85555', '86021', '861', '864233', '86688', '87021', '87066', '87077', '87121', '87131', '8714714', '872', '87239', '87575', '8800', '88039', '88066', '88088', '88222', '88600', '88800', '8883', '88888', '89034', '89070', '89080', '89105', '89545', '89555', '89693', '89938', '8am', '8ball', '8lb', '8p', '8pm', '8th', '8wp', '900', '9061100010', '910', '9280114', '92h', '930', '945', '95', '9755', '97n7qp', '99', '9996', '9ae', '9am', '9ja', '9pm', '9t', '9th', '9yt', '____', 'a21', 'aa', 'aah', 'aaniye', 'aaooooright', 'aathi', 'ab', 'abdomen', 'abel', 'aberdeen', 'abi', 'ability', 'abiola', 'abj', 'able', 'abnormally', 'aboutas', 'abroad', 'absence', 'absolutely', 'absolutly', 'abt', 'abta', 'aburo', 'abusers', 'ac', 'academic', 'acc', 'accent', 'accenture', 'accept', 'access', 'accessible', 'accidant', 'accident', 'accidentally', 'accommodation', 'accommodationvouchers', 'accomodate', 'accordin', 'accordingly', 'account', 'accounting', 'accounts', 'accumulation', 'achan', 'ache', 'acid', 'acl03530150pm', 'acnt', 'aco', 'act', 'acted', 'actin', 'action', 'activ8', 'activate', 'active', 'activities', 'actor', 'actual', 'actually', 'ad', 'adam', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'adding', 'address', 'adds', 'adi', 'adjustable', 'admin', 'admirer', 'admission', 'admit', 'adore', 'adoring', 'adp', 'adress', 'adrian', 'ads', 'adult', 'adults', 'advance', 'adventure', 'adventuring', 'advice', 'advise', 'advising', 'aeronautics', 'aeroplane', 'affair', 'affairs', 'affection', 'affectionate', 'affidavit', 'afford', 'afghanistan', 'afraid', 'africa', 'african', 'aft', 'afternon', 'afternoon', 'afternoons', 'aftr', 'ag', 'age', 'age16', 'age23', 'agency', 'agent', 'agents', 'ages', 'agidhane', 'aging', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahhh', 'ahhhh', 'ahmad', 'ahold', 'aid', 'aids', 'aig', 'aight', 'ain', 'aint', 'air', 'air1', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aka', 'akon', 'al', 'alaikkum', 'alaipayuthe', 'album', 'alcohol', 'aldrine', 'alert', 'alex', 'alfie', 'algarve', 'algorithms', 'alian', 'alibi', 'alive', 'allah', 'allalo', 'alle', 'allo', 'allow', 'allowed', 'allows', 'alot', 'alright', 'alrite', 'alter', 'alternative', 'alto18', 'aluable', 'alwa', 'alwys', 'amanda', 'amazing', 'ambitious', 'american', 'amigos', 'amk', 'amla', 'amma', 'ammae', 'amore', 'amp', 'amplikater', 'amrca', 'amrita', 'amt', 'amused', 'amy', 'ana', 'anal', 'anand', 'anderson', 'andre', 'andres', 'andrews', 'andros', 'angels', 'angry', 'animal', 'animation', 'anjie', 'anjola', 'anna', 'annie', 'anniversary', 'announced', 'announcement', 'annoyin', 'annoying', 'anot', 'ans', 'ansr', 'answer', 'answered', 'answerin', 'answering', 'answers', 'answr', 'antelope', 'anthony', 'anti', 'antibiotic', 'anybody', 'anymore', 'anyones', 'anyplaces', 'anythin', 'anythingtomorrow', 'anytime', 'anyways', 'aom', 'apart', 'apartment', 'apes', 'apeshit', 'aphex', 'apnt', 'apo', 'apologetic', 'apologise', 'apology', 'app', 'apparently', 'appeal', 'appear', 'appendix', 'applebees', 'apples', 'application', 'apply', 'applyed', 'applying', 'appointment', 'appreciate', 'appreciated', 'approaches', 'approaching', 'appropriate', 'approve', 'approx', 'apps', 'appt', 'april', 'aproach', 'apt', 'aptitude', 'ar', 'arab', 'arabian', 'arcade', 'archive', 'ard', 'area', 'aren', 'arent', 'aretaking', 'areyouunique', 'argh', 'argue', 'arguing', 'argument', 'arguments', 'aries', 'arises', 'arithmetic', 'arm', 'armand', 'armenia', 'arms', 'arng', 'arngd', 'arnt', 'arr', 'arrange', 'arranging', 'arrested', 'arrive', 'arsenal', 'art', 'arts', 'arul', 'arun', 'asa', 'asap', 'asda', 'ashes', 'ashley', 'asia', 'asian', 'asjesus', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'aspects', 'ass', 'assessment', 'asshole', 'associate', 'assume', 'assumed', 'asthere', 'asthma', 'astrology', 'asusual', 'ate', 'athletic', 'athome', 'atlanta', 'atlast', 'atleast', 'atm', 'atrocious', 'attached', 'attack', 'attempt', 'atten', 'attend', 'attended', 'attending', 'attention', 'attitude', 'attraction', 'attractive', 'attributed', 'atural', 'auction', 'audition', 'audrey', 'audrie', 'august', 'aunt', 'aunties', 'aunts', 'aunty', 'aust', 'australia', 'authorise', 'auto', 'autocorrect', 'av', 'ava', 'availa', 'available', 'avalarr', 'avatar', 'ave', 'avenge', 'avent', 'avin', 'avo', 'avoid', 'avoiding', 'avoids', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'awkward', 'aww', 'awww', 'axel', 'ay', 'ayn', 'ayo', 'b4', 'b4190604', 'b4280703', 'b4u', 'b4utele', 'ba', 'ba128nnfwfly150ppm', 'babe', 'babes', 'babies', 'baby', 'babygoodbye', 'babysit', 'bac', 'backdoor', 'bad', 'badly', 'badrith', 'bag', 'bags', 'bahamas', 'baig', 'bailiff', 'bajarangabali', 'bak', 'bakrid', 'balance', 'ball', 'baller', 'bam', 'bambling', 'band', 'bandages', 'bang', 'bangb', 'bangbabes', 'bani', 'bank', 'banks', 'banned', 'banneduk', 'banter', 'bao', 'bar', 'barcelona', 'bare', 'barely', 'barkleys', 'barmed', 'barolla', 'barred', 'barrel', 'bars', 'base', 'based', 'bash', 'basic', 'basically', 'basket', 'basketball', 'basq', 'bat', 'batch', 'batchlor', 'bath', 'bathe', 'bathing', 'bathroom', 'batsman', 'battery', 'battle', 'bawling', 'bay', 'bb', 'bbc', 'bbd', 'bbdeluxe', 'bbq', 'bc', 'bcaz', 'bck', 'bcm', 'bcm1896wc1n3xx', 'bcm4284', 'bcmsfwc1n3xx', 'bcoz', 'bcs', 'bcum', 'bcums', 'bcz', 'bday', 'beach', 'beads', 'bear', 'bears', 'beauties', 'beautiful', 'beauty', 'bec', 'becaus', 'becoz', 'becz', 'bed', 'bedrm', 'bedroom', 'beehoon', 'beendropping', 'beer', 'beerage', 'befor', 'beg', 'beggar', 'begging', 'begin', 'behalf', 'behave', 'bein', 'believe', 'belive', 'bell', 'belligerent', 'belly', 'belong', 'belovd', 'belt', 'ben', 'bend', 'beneath', 'beneficiary', 'bennys', 'bergkamp', 'best', 'best1', 'bet', 'beta', 'beth', 'betta', 'better', 'bettersn', 'bettr', 'bevies', 'beware', 'bf', 'bffs', 'bfore', 'bhaji', 'bhaskar', 'bhayandar', 'bian', 'biatch', 'bid', 'bids', 'big', 'bigger', 'biggest', 'bike', 'billed', 'billion', 'bills', 'billy', 'bimbo', 'bin', 'biola', 'bird', 'birds', 'birla', 'biro', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bitching', 'bite', 'bites', 'bits', 'biz', 'bk', 'black', 'blackberry', 'blake', 'blame', 'blank', 'blanked', 'blanket', 'blankets', 'blastin', 'bleak', 'bless', 'blessing', 'blessings', 'blimey', 'blind', 'block', 'blocked', 'blog', 'blogging', 'blogspot', 'bloke', 'blokes', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blowing', 'blown', 'blu', 'blue', 'bluetooth', 'bluff', 'blur', 'bluray', 'bmw', 'board', 'boat', 'boatin', 'body', 'boggy', 'bognor', 'bold', 'bold2', 'bollox', 'boltblue', 'bomb', 'bone', 'bong', 'bonus', 'boo', 'boobs', 'book', 'booked', 'bookedthe', 'booking', 'bookmark', 'books', 'bookshelf', 'boooo', 'boost', 'booty', 'bootydelious', 'borderline', 'bored', 'borin', 'boring', 'born', 'borrow', 'boss', 'boston', 'bother', 'bothering', 'bottle', 'bought', 'boundaries', 'bout', 'bowa', 'bowl', 'box', 'box139', 'box177', 'box245c2150pm', 'box326', 'box334', 'box334sk38ch', 'box39822', 'box403', 'box420', 'box42wr29c', 'box61', 'box95qu', 'box97n7qp', 'boy', 'boye', 'boyf', 'boyfriend', 'boys', 'boytoy', 'bpo', 'brah', 'brain', 'braindance', 'brainless', 'brains', 'brainy', 'brand', 'brandy', 'brats', 'braved', 'bray', 'brb', 'brdget', 'bread', 'breadstick', 'break', 'breaker', 'breakfast', 'breakin', 'breaking', 'breaks', 'breath', 'breathe', 'breathe1', 'breather', 'breezy', 'bribe', 'bridge', 'bridgwater', 'brief', 'bright', 'brilliant', 'brilliantly', 'brin', 'bring', 'bringing', 'brings', 'brisk', 'bristol', 'british', 'britney', 'bro', 'broad', 'broadband', 'broke', 'broken', 'brolly', 'bros', 'broth', 'brothas', 'brother', 'brothers', 'brought', 'brown', 'brownie', 'brownies', 'browser', 'bruce', 'bruv', 'bslvyl', 'bsn', 'bsnl', 'bstfrnd', 'bt', 'btw', 'btwn', 'bucks', 'bud', 'buddy', 'buddys', 'budget', 'buen', 'buff', 'buffet', 'bugis', 'build', 'building', 'built', 'bulbs', 'bull', 'bullshit', 'bunkers', 'buns', 'burden', 'burgundy', 'burial', 'burn', 'burning', 'burns', 'burnt', 'burrito', 'bus', 'bus8', 'buses', 'business', 'busty', 'busy', 'butt', 'buttheres', 'butting', 'buttons', 'buy', 'buyer', 'buyers', 'buying', 'buzy', 'buzz', 'buzzzz', 'bw', 'bx', 'bx420', 'byatch', 'bye', 'c52', 'cab', 'cabin', 'cafe', 'cage', 'cake', 'cakes', 'cal', 'calculated', 'calculation', 'cali', 'calicut', 'california', 'call2optout', 'callback', 'callcost', 'callcost150ppmmobilesvary', 'calld', 'called', 'caller', 'callers', 'callertune', 'callfreefone', 'callin', 'calling', 'callon', 'calls', 'calls1', 'calm', 'cam', 'camcorder', 'came', 'camera', 'camp', 'campus', 'camry', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'canlove', 'cann', 'canname', 'cantdo', 'canteen', 'capital', 'cappuccino', 'caps', 'captain', 'captaining', 'car', 'card', 'cardiff', 'cardin', 'cards', 'care', 'careabout', 'cared', 'career', 'careers', 'careful', 'carefully', 'cares', 'caring', 'carlie', 'carlin', 'carlos', 'carly', 'carolina', 'caroline', 'carpark', 'carry', 'carryin', 'cars', 'cartons', 'cartoon', 'case', 'cash', 'cashbin', 'cashed', 'cashto', 'casing', 'cast', 'castor', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'caveboy', 'cbe', 'cc', 'cc100p', 'ccna', 'cd', 'cdgt', 'cds', 'celeb', 'celebrate', 'celebration', 'celebrations', 'cell', 'center', 'centre', 'century', 'cer', 'cereals', 'ceri', 'certainly', 'certificate', 'cha', 'chachi', 'chad', 'chain', 'challenge', 'champlaxigating', 'champneys', 'chance', 'chances', 'change', 'changed', 'changes', 'changing', 'channel', 'chapel', 'chaps', 'character', 'charge', 'charged', 'charges', 'charity', 'charles', 'charlie', 'charming', 'chart', 'charts', 'chase', 'chasing', 'chat', 'chat80155', 'chatlines', 'chatter', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi', 'check', 'checkboxes', 'checked', 'checkin', 'checking', 'checkup', 'cheek', 'cheer', 'cheered', 'cheers', 'cheery', 'cheese', 'cheesy', 'cheetos', 'chef', 'chennai', 'cherthala', 'chest', 'chex', 'cheyyamo', 'chg', 'chic', 'chick', 'chicken', 'chickened', 'chief', 'chik', 'chikku', 'child', 'childish', 'children', 'childrens', 'chile', 'chill', 'chillaxin', 'chillin', 'china', 'chinatown', 'chinchillas', 'chinese', 'chinky', 'chinnu', 'chiong', 'chip', 'chit', 'chk', 'chloe', 'chocolate', 'choice', 'choices', 'choose', 'choosing', 'chop', 'chords', 'chores', 'chosen', 'chrgd', 'christ', 'christians', 'christmas', 'christmassy', 'chuck', 'chuckin', 'church', 'ciao', 'cine', 'cinema', 'citizen', 'city', 'citylink', 'claim', 'claimcode', 'claims', 'claire', 'clarify', 'clark', 'clas', 'class', 'classes', 'classic', 'claypot', 'cld', 'clean', 'cleaning', 'clear', 'cleared', 'clearer', 'clearing', 'clearly', 'clever', 'click', 'cliff', 'cliffs', 'clip', 'clock', 'clocks', 'clos1', 'close', 'closeby', 'closed', 'closer', 'closes', 'closingdate04', 'clothes', 'cloud', 'clover', 'club', 'clubmoby', 'clubsaisai', 'cm', 'cm2', 'cmon', 'cn', 'cnl', 'cnn', 'coach', 'coast', 'coat', 'coaxing', 'coccooning', 'cochin', 'cock', 'cocksuckers', 'coco', 'code', 'coffee', 'coherently', 'coimbatore', 'coin', 'coincidence', 'coins', 'colany', 'cold', 'colin', 'collapsed', 'colleagues', 'collect', 'collected', 'collecting', 'collection', 'colleg', 'college', 'color', 'colour', 'colours', 'com', 'com1win150ppmx3age16', 'comb', 'combination', 'combine', 'come', 'comedy', 'comes', 'comfey', 'comfort', 'comin', 'coming', 'comment', 'commercial', 'commit', 'common', 'community', 'como', 'comp', 'companies', 'companion', 'company', 'compare', 'compass', 'compensation', 'competition', 'complacent', 'complain', 'complaining', 'complaint', 'complementary', 'complete', 'completed', 'completely', 'completes', 'complexities', 'complimentary', 'compliments', 'comprehensive', 'computer', 'computerless', 'comuk', 'conacted', 'concentrate', 'concerned', 'concert', 'conclusion', 'condition', 'conditions', 'conducts', 'conected', 'conference', 'confidence', 'configure', 'confirm', 'confirmd', 'confirmed', 'conform', 'confused', 'confuses', 'congrats', 'congratulation', 'congratulations', 'connect', 'connection', 'connections', 'cons', 'consensus', 'consent', 'conserve', 'consider', 'considering', 'console', 'constant', 'constantly', 'contact', 'contacted', 'contacts', 'content', 'contention', 'contents', 'continent', 'continue', 'contract', 'contribute', 'control', 'convenience', 'conversations', 'converter', 'convey', 'convinced', 'convincing', 'cook', 'cooked', 'cookies', 'cooking', 'cool', 'cooped', 'cooperative', 'copies', 'coping', 'cops', 'copy', 'corect', 'cornwall', 'corporation', 'correct', 'correction', 'corrupt', 'corvettes', 'cos', 'cosign', 'cost', 'costa', 'costing', 'costs', 'costume', 'costumes', 'couch', 'cougar', 'cough', 'coughing', 'coulda', 'couldn', 'count', 'countin', 'countinlots', 'country', 'counts', 'couple', 'courage', 'courageous', 'course', 'court', 'courtroom', 'cousin', 'cover', 'covers', 'coz', 'cozy', 'cps', 'cr', 'cr01327bt', 'cr9', 'crack', 'craigslist', 'crammed', 'cramps', 'crap', 'crash', 'crashed', 'crashing', 'crave', 'craving', 'craziest', 'crazy', 'crazyin', 'cream', 'created', 'creative', 'creativity', 'credit', 'credited', 'credits', 'creepy', 'cres', 'cribbs', 'cricket', 'cricketer', 'cried', 'crisis', 'crore', 'cross', 'crossing', 'croydon', 'crucial', 'crucify', 'cruel', 'cruise', 'cruisin', 'cs', 'csbcm4235wc1n3xx', 'csh11', 'cst', 'cstore', 'cthen', 'ctla', 'cts', 'ctxt', 'cu', 'cuck', 'cud', 'cuddle', 'cuddled', 'cuddling', 'cudnt', 'culdnt', 'cultures', 'cum', 'cumin', 'cumming', 'cup', 'cuppa', 'curious', 'current', 'currently', 'curry', 'cust', 'custcare', 'custom', 'customer', 'customercare', 'customers', 'customersqueries', 'cut', 'cute', 'cutefrnd', 'cutest', 'cutie', 'cutting', 'cuz', 'cw25wx', 'cya', 'cyclists', 'da', 'dabooks', 'dad', 'daddy', 'dai', 'daily', 'dammit', 'damn', 'dan', 'dancce', 'dance', 'dancin', 'dancing', 'dang', 'danger', 'dangerous', 'dao', 'dare', 'dark', 'darkest', 'darkness', 'darlin', 'darling', 'darlings', 'darren', 'dartboard', 'das', 'dasara', 'dat', 'date', 'dates', 'dating', 'datz', 'dave', 'dawns', 'day', 'days', 'daytime', 'daywith', 'db', 'dbuk', 'dead', 'deal', 'dealing', 'dear', 'dear1', 'dearer', 'dearly', 'death', 'dec', 'decades', 'december', 'decent', 'decide', 'decided', 'deciding', 'decimal', 'decision', 'decisions', 'decking', 'declare', 'decorating', 'dedicate', 'dedicated', 'deep', 'deepak', 'deepest', 'deer', 'deeraj', 'def', 'defeat', 'defer', 'deficient', 'definite', 'definitely', 'defo', 'degree', 'dehydrated', 'dehydration', 'del', 'delay', 'delayed', 'delete', 'deleted', 'delhi', 'delicious', 'delivered', 'deliveredtomorrow', 'delivery', 'deltomorrow', 'deluxe', 'dem', 'den', 'dengra', 'denis', 'dent', 'dental', 'dentist', 'dentists', 'deny', 'department', 'dependable', 'dependents', 'depends', 'deposit', 'deposited', 'depressed', 'depression', 'dept', 'der', 'derek', 'derp', 'description', 'designation', 'desires', 'desparate', 'desperate', 'despite', 'destination', 'destiny', 'detailed', 'details', 'determine', 'determined', 'detroit', 'deus', 'develop', 'developer', 'devils', 'dey', 'dhanush', 'dhina', 'dhoni', 'dhorte', 'di', 'dial', 'diamonds', 'diapers', 'dice', 'dick', 'dict', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diesel', 'diet', 'dieting', 'diff', 'differ', 'difference', 'different', 'difficult', 'difficulties', 'dificult', 'digital', 'digits', 'dignity', 'dileep', 'dime', 'dimension', 'din', 'dine', 'dinero', 'dinner', 'dint', 'dip', 'dippeditinadew', 'direct', 'directly', 'director', 'directors', 'dirt', 'dirtiest', 'dirty', 'dis', 'disappeared', 'disappointment', 'disaster', 'disastrous', 'disc', 'disclose', 'disconnect', 'disconnected', 'discount', 'discreet', 'discuss', 'discussed', 'diseases', 'dislikes', 'dismay', 'dismissial', 'display', 'distance', 'disturb', 'disturbance', 'disturbing', 'division', 'divorce', 'diwali', 'dizzamn', 'dizzee', 'dl', 'dlf', 'dload', 'dnot', 'dnt', 'dob', 'dobby', 'doc', 'docks', 'docs', 'doctor', 'doctors', 'documents', 'dodda', 'dodgey', 'does', 'doesdiscount', 'doesn', 'doesnt', 'dog', 'dogbreath', 'doggin', 'dogging', 'doggy', 'dogs', 'dogwood', 'doin', 'doing', 'doit', 'dokey', 'doll', 'dollar', 'dollars', 'dolls', 'dom', 'domain', 'don', 'donate', 'donno', 'dont', 'dontcha', 'donyt', 'dooms', 'door', 'doors', 'dorm', 'dorothy', 'dot', 'double', 'doubles', 'doubt', 'doug', 'dough', 'download', 'downloaded', 'downloads', 'downon', 'downs', 'dozens', 'dps', 'dr', 'dracula', 'dramastorm', 'dramatic', 'drastic', 'draw', 'dreading', 'dream', 'dreams', 'dreamz', 'dress', 'dresser', 'drink', 'drinkin', 'drinking', 'drinks', 'drivby', 'drive', 'driver', 'drivin', 'driving', 'drizzling', 'drms', 'drop', 'dropped', 'drops', 'drove', 'drpd', 'drug', 'drugs', 'drum', 'drunk', 'drunkard', 'drunken', 'dry', 'dryer', 'dsn', 'dt', 'dubsack', 'duchess', 'ducking', 'dude', 'dudes', 'dudette', 'duffer', 'dull', 'dumb', 'dump', 'dun', 'dungerees', 'dunno', 'duo', 'durban', 'durham', 'dusk', 'dust', 'duvet', 'dvd', 'dvg', 'dysentry', 'e14', 'eachother', 'earlier', 'earliest', 'early', 'earn', 'earning', 'earth', 'easier', 'easiest', 'easily', 'east', 'eastenders', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ec2a', 'eckankar', 'ecstacy', 'ed', 'edge', 'edison', 'edition', 'edrunk', 'edu', 'education', 'educational', 'edukkukayee', 'edward', 'edwards', 'ee', 'eek', 'eerie', 'effect', 'effects', 'efreefone', 'egg', 'eggs', 'eh', 'eh74rr', 'eighth', 'eightish', 'eire', 'el', 'ela', 'elaborate', 'elaborating', 'elaine', 'elama', 'eldest', 'elections', 'electricity', 'elephant', 'elliot', 'ello', 'em', 'email', 'emailed', 'embarassed', 'embarrassed', 'embassy', 'emc1', 'emergency', 'emerging', 'emigrated', 'emotion', 'employee', 'employer', 'en', 'end', 'ended', 'ending', 'endless', 'endof', 'endowed', 'ends', 'enemies', 'enemy', 'energy', 'eng', 'engaged', 'engalnd', 'engin', 'england', 'english', 'enjoy', 'enjoyed', 'enjoyin', 'enjoying', 'enketa', 'ennal', 'ente', 'enter', 'entered', 'enters', 'entey', 'entire', 'entirely', 'entitled', 'entrepreneurs', 'entropication', 'entry', 'entry41', 'enufcredeit', 'enuff', 'envelope', 'environment', 'envy', 'eppolum', 'epsilon', 'equally', 'er', 'ere', 'ericson', 'ericsson', 'erm', 'erode', 'erotic', 'error', 'errors', 'eruku', 'escape', 'ese', 'eshxxxxxxxxxxx', 'espe', 'especially', 'esplanade', 'essay', 'essential', 'establish', 'eta', 'ettans', 'euro', 'euro2004', 'eurodisinc', 'europe', 'evaluation', 'evaporated', 'eve', 'eveb', 'evening', 'evenings', 'events', 'eventually', 'every1', 'everybody', 'everyboy', 'everyday', 'everyso', 'everythin', 'everytime', 'evey', 'evil', 'evn', 'evng', 'evone', 'evr', 'evrey', 'evry', 'evry1', 'evrydy', 'ew', 'ex', 'exact', 'exactly', 'exam', 'exams', 'excellent', 'exciting', 'excuse', 'excuses', 'exe', 'executive', 'exercise', 'exeter', 'exhaust', 'exhausted', 'exhibition', 'exist', 'exmpel', 'exorcist', 'exp', 'expect', 'expected', 'expecting', 'expects', 'expensive', 'experience', 'experiment', 'expert', 'expired', 'expires', 'explain', 'explicit', 'explicitly', 'explosive', 'exposes', 'express', 'expression', 'expressoffer', 'ext', 'exterminator', 'extra', 'extreme', 'ey', 'eye', 'eyed', 'eyes', 'f4q', 'fa', 'fab', 'faber', 'face', 'facebook', 'facilities', 'fact', 'facts', 'faded', 'faggot', 'faglord', 'failed', 'failing', 'fails', 'failure', 'fainting', 'fair', 'faith', 'fake', 'fakeye', 'fal', 'falconerf', 'fall', 'fallen', 'falling', 'falls', 'fals', 'famamus', 'family', 'famous', 'fan', 'fancied', 'fancy', 'fans', 'fantasies', 'fantastic', 'fantasy', 'far', 'farm', 'farrell', 'farting', 'fast', 'faster', 'fastest', 'fat', 'father', 'fathima', 'fats', 'fatty', 'fault', 'fav', 'fave', 'favor', 'favour', 'favourite', 'fb', 'fear', 'feathery', 'features', 'feb', 'february', 'fed', 'fedex', 'feed', 'feel', 'feelin', 'feeling', 'feels', 'fees', 'feet', 'fell', 'fellow', 'felt', 'female', 'festival', 'fetch', 'fetching', 'fever', 'ffectionate', 'fffff', 'ffffffffff', 'ffffuuuuuuu', 'fgkslpo', 'fgkslpopw', 'fidalfication', 'field', 'fieldof', 'fiend', 'fifa', 'fifth', 'fight', 'fighting', 'fightng', 'fights', 'figure', 'figures', 'figuring', 'file', 'files', 'filled', 'filling', 'fills', 'film', 'films', 'filth', 'filthy', 'filthyguys', 'final', 'finalise', 'finally', 'finance', 'financial', 'finding', 'finds', 'fine', 'finest', 'fingers', 'finish', 'finishd', 'finished', 'finishes', 'finishing', 'fink', 'finn', 'fired', 'firefox', 'fireplace', 'fires', 'firsg', 'fish', 'fishhead', 'fishrman', 'fit', 'fiting', 'fix', 'fixed', 'fixedline', 'fixes', 'flag', 'flaked', 'flaky', 'flame', 'flash', 'flat', 'flatter', 'flavour', 'flea', 'fletcher', 'flew', 'flies', 'flight', 'flights', 'flim', 'flip', 'flirt', 'flirting', 'flirtparty', 'floating', 'flood', 'floor', 'florida', 'flower', 'flowers', 'flowing', 'fluids', 'flung', 'flurries', 'fly', 'flying', 'flyng', 'fml', 'fne', 'foley', 'folks', 'follow', 'followed', 'followin', 'following', 'fond', 'fone', 'foned', 'fones', 'fonin', 'food', 'fool', 'fooled', 'fools', 'foot', 'football', 'footie', 'force', 'forced', 'foreign', 'forever', 'forevr', 'forfeit', 'forget', 'forgets', 'forgiven', 'forgiveness', 'forgot', 'forgotten', 'forgt', 'form', 'formal', 'format', 'formatting', 'forms', 'forth', 'forum', 'forums', 'forward', 'forwarded', 'forwarding', 'foundurself', 'fourth', 'foward', 'fowler', 'fps', 'fr', 'fraction', 'fran', 'frank', 'frankie', 'franxx', 'franyxxxxx', 'frauds', 'freak', 'freaking', 'freaky', 'fredericksburg', 'free', 'free2day', 'freedom', 'freefone', 'freek', 'freely', 'freemsg', 'freephone', 'freezing', 'freinds', 'fren', 'french', 'frens', 'freshers', 'fret', 'fri', 'friday', 'fridge', 'fried', 'friend', 'friends', 'friendsare', 'friendship', 'friendships', 'fringe', 'frm', 'frmcloud', 'frnd', 'frnds', 'frndship', 'frndshp', 'frndz', 'frnt', 'frog', 'fromm', 'frontierville', 'frosty', 'fruit', 'frwd', 'ft', 'fuck', 'fucked', 'fuckin', 'fucking', 'fucks', 'fujitsu', 'ful', 'fulfil', 'fullonsms', 'fumbling', 'fun', 'function', 'functions', 'fund', 'funeral', 'funk', 'funky', 'funny', 'funs', 'furniture', 'fusion', 'future', 'fuuuuck', 'fwiw', 'fyi', 'g2', 'g696ga', 'ga', 'gail', 'gailxx', 'gain', 'gained', 'gal', 'galileo', 'gals', 'gam', 'game', 'games', 'gamestar', 'gandhipuram', 'ganesh', 'gang', 'gap', 'gaps', 'garage', 'garbage', 'garden', 'gardener', 'gari', 'garments', 'gary', 'gas', 'gastroenteritis', 'gate', 'gauge', 'gautham', 'gauti', 'gave', 'gay', 'gayle', 'gays', 'gaytextbuddy', 'gaze', 'gbp', 'gbp1', 'gbp4', 'gbp5', 'gd', 'ge', 'gee', 'geeee', 'geeeee', 'gei', 'gender', 'general', 'generally', 'genes', 'genius', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'gep', 'ger', 'germany', 'get4an18th', 'getiing', 'geting', 'gets', 'getstop', 'gettin', 'getting', 'getzed', 'gf', 'ghodbandar', 'ghost', 'gibbs', 'gift', 'gifted', 'gifts', 'giggle', 'gigolo', 'gimme', 'gimmi', 'gin', 'girl', 'girlfrnd', 'girlie', 'girls', 'gist', 'giv', 'given', 'gives', 'giving', 'glad', 'glands', 'glass', 'glo', 'global', 'glorious', 'glory', 'gloucesterroad', 'gm', 'gn', 'gnarls', 'gnt', 'gnun', 'go2', 'goal', 'goals', 'gobi', 'god', 'gods', 'goes', 'goggles', 'goigng', 'goin', 'goin2bed', 'going', 'gokila', 'gold', 'golddigger', 'golden', 'goldviking', 'golf', 'gon', 'gona', 'gone', 'gong', 'gonna', 'gonnamissu', 'good', 'goodfriend', 'goodies', 'goodmate', 'goodmorning', 'goodnight', 'goodnite', 'goodnoon', 'goodo', 'goods', 'goodtime', 'google', 'gopalettan', 'gorgeous', 'goss', 'gossip', 'got', 'gota', 'gotbabes', 'goto', 'gotta', 'gotten', 'goverment', 'govt', 'gprs', 'gr8', 'gr8fun', 'gr8prizes', 'grab', 'grace', 'graduated', 'grahmbell', 'gram', 'grams', 'grand', 'grandfather', 'grandma', 'granite', 'granted', 'graphics', 'grasp', 'grateful', 'grave', 'gravel', 'gravity', 'gravy', 'gray', 'gre', 'great', 'greatest', 'greatly', 'greece', 'green', 'greet', 'greeting', 'greetings', 'grinder', 'grins', 'grinule', 'grooved', 'groovy', 'groovying', 'ground', 'group', 'grow', 'growing', 'grown', 'grumble', 'grumpy', 'gsex', 'gsoh', 'gt', 'gua', 'guai', 'guarantee', 'guaranteed', 'gucci', 'gud', 'gudni8', 'gudnite', 'gudnyt', 'guess', 'guessed', 'guessin', 'guessing', 'guidance', 'guide', 'guides', 'guild', 'guilty', 'guitar', 'gurl', 'gut', 'guy', 'guys', 'gv', 'gving', 'gym', 'gymnastics', 'gynae', 'gyno', 'ha', 'habba', 'habit', 'hack', 'hadn', 'haf', 'haha', 'hahaha', 'hai', 'hail', 'hair', 'haircut', 'haiyoh', 'haiz', 'half', 'half8th', 'hallaq', 'halloween', 'ham', 'hamper', 'hamster', 'hand', 'handed', 'handle', 'hands', 'handset', 'handsome', 'handsomes', 'hang', 'hanger', 'hangin', 'hanging', 'hanks', 'hannaford', 'hanuman', 'hanumanji', 'happen', 'happend', 'happened', 'happenin', 'happening', 'happens', 'happier', 'happily', 'happiness', 'happy', 'hard', 'hardcore', 'harder', 'hardest', 'hardly', 'hari', 'harish', 'harlem', 'harri', 'harry', 'hasbro', 'hasn', 'hassling', 'hat', 'hate', 'hates', 'haughaighgtujhyguj', 'haul', 'haunt', 'hav', 'hav2hear', 'hava', 'haven', 'havent', 'haventcn', 'havin', 'having', 'havnt', 'hcl', 'hdd', 'head', 'headache', 'heading', 'heads', 'headset', 'headstart', 'heal', 'healer', 'healthy', 'heap', 'hear', 'heard', 'hearin', 'hearing', 'heart', 'hearted', 'hearts', 'heat', 'heavily', 'heavy', 'hectic', 'hee', 'heehee', 'hehe', 'height', 'held', 'helen', 'helens', 'hell', 'hella', 'hello', 'helloooo', 'help', 'help08714742804', 'help08718728876', 'helpful', 'helping', 'helps', 'henry', 'hero', 'heroes', 'heron', 'hes', 'hesitant', 'hesitate', 'hex', 'hey', 'hf8', 'hg', 'hhahhaahahah', 'hi', 'hidden', 'hide', 'hides', 'high', 'highest', 'hilarious', 'hill', 'hills', 'hillsborough', 'himso', 'hint', 'hip', 'hiphop', 'hire', 'history', 'hit', 'hitman', 'hits', 'hitter', 'hittng', 'hiya', 'hl', 'hlday', 'hlp', 'hm', 'hme', 'hmm', 'hmmm', 'hmmmm', 'hmmross', 'hmph', 'hmv', 'ho', 'hockey', 'hogidhe', 'hol', 'holby', 'hold', 'holder', 'holding', 'hole', 'holiday', 'holla', 'hollalater', 'hols', 'holy', 'home', 'homeowners', 'hon', 'honest', 'honestly', 'honesty', 'honey', 'honeybee', 'honeymoon', 'hont', 'hoo', 'hook', 'hooked', 'hoops', 'hop', 'hope', 'hoped', 'hopeful', 'hopefully', 'hopes', 'hoping', 'hor', 'horniest', 'horny', 'horo', 'horrible', 'horse', 'hospital', 'hospitals', 'host', 'hostel', 'hostile', 'hot', 'hotel', 'hotels', 'hotmail', 'hour', 'hours', 'house', 'houseful', 'housewives', 'housework', 'housing', 'howard', 'howda', 'howdy', 'hows', 'howu', 'howz', 'hp', 'hp20', 'hppnss', 'hr', 'hrishi', 'hrs', 'hsbc', 'html', 'http', 'hu', 'hubby', 'hug', 'huge', 'hugging', 'huh', 'hui', 'huiming', 'hum', 'hun', 'hundreds', 'hungry', 'hunks', 'hunny', 'hunt', 'hunting', 'hurried', 'hurry', 'hurt', 'hurts', 'husband', 'hustle', 'hut', 'hv', 'hv9d', 'hvae', 'hw', 'hyde', 'hype', 'hypertension', 'hypotheticalhuagauahahuagahyuhagga', 'iam', 'ias', 'ibh', 'ibhltd', 'ibiza', 'ibm', 'ibn', 'ibuprofens', 'ic', 'ice', 'icicibank', 'icky', 'icmb3cktz8r7', 'icon', 'id', 'idc', 'idea', 'ideal', 'ideas', 'identifier', 'idew', 'idiot', 'idk', 'idps', 'idu', 'iff', 'ifink', 'ig11', 'ignore', 'ignoring', 'ihave', 'ijust', 'ikea', 'ikno', 'iknow', 'il', 'ileave', 'ill', 'illness', 'illspeak', 'ilol', 'im', 'images', 'imagination', 'imagine', 'imat', 'imf', 'img', 'imma', 'immediately', 'imp', 'impatient', 'impede', 'important', 'importantly', 'imposed', 'impossible', 'imposter', 'impress', 'impressed', 'impression', 'impressively', 'improve', 'improved', 'in2', 'inch', 'inches', 'incident', 'inclu', 'include', 'including', 'inclusive', 'incomm', 'inconsiderate', 'inconvenience', 'inconvenient', 'incorrect', 'increase', 'incredible', 'increments', 'inde', 'independence', 'index', 'india', 'indian', 'indians', 'indicate', 'individual', 'indyarocks', 'inever', 'infact', 'infections', 'infernal', 'info', 'inform', 'information', 'informed', 'infra', 'infront', 'ing', 'ingredients', 'initiate', 'ink', 'inlude', 'inmind', 'innings', 'innocent', 'inperialmusic', 'inpersonation', 'inr', 'insects', 'insha', 'inshah', 'inside', 'inspection', 'inst', 'installation', 'instant', 'instantly', 'instead', 'instituitions', 'instructions', 'insurance', 'intelligent', 'intend', 'intention', 'intentions', 'interested', 'interesting', 'interflora', 'interfued', 'internet', 'interview', 'interviews', 'interviw', 'intrepid', 'intro', 'intrude', 'invaders', 'invest', 'invitation', 'invite', 'invited', 'inviting', 'invnted', 'involve', 'involved', 'iouri', 'ip', 'ip4', 'ipad', 'ipads', 'iphone', 'ipod', 'iq', 'iraq', 'irene', 'iriver', 'iron', 'ironing', 'irritated', 'irritates', 'irritating', 'irritation', 'irulinae', 'iscoming', 'ish', 'ishtamayoo', 'island', 'islands', 'isn', 'isnt', 'issue', 'issues', 'italian', 'itcould', 'items', 'iter', 'itna', 'itried2tell', 'itwhichturnedinto', 'itxt', 'itz', 'ivatte', 'ive', 'iwana', 'iwas', 'iz', 'izzit', 'j89', 'jabo', 'jack', 'jacket', 'jackpot', 'jackson', 'jada', 'jade', 'jam', 'james', 'jamster', 'jamz', 'jan', 'janarige', 'jane', 'janinexx', 'january', 'jap', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jaykwon', 'jazz', 'jb', 'jd', 'jealous', 'jeans', 'jeetey', 'jeevithathile', 'jelly', 'jen', 'jenny', 'jeremiah', 'jerk', 'jerry', 'jersey', 'jess', 'jesus', 'jet', 'jewelry', 'jez', 'ji', 'jia', 'jiayin', 'jiu', 'jjc', 'jo', 'joanna', 'job', 'jobs', 'jobyet', 'jocks', 'jod', 'jog', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'joker', 'jokes', 'jokin', 'joking', 'jolly', 'jolt', 'jon', 'jones', 'jontin', 'jordan', 'jorge', 'jos', 'jot', 'journey', 'joy', 'joys', 'jp', 'js', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juicy', 'jul', 'july', 'jump', 'jumpers', 'june', 'jungle', 'junna', 'jurong', 'jus', 'just', 'justbeen', 'justify', 'justthought', 'juswoke', 'juz', 'k52', 'k718', 'kadeem', 'kaiez', 'kaila', 'kaitlyn', 'kalainar', 'kalisidare', 'kallis', 'kama', 'kanagu', 'kano', 'kappa', 'karaoke', 'karnan', 'karo', 'kate', 'katexxx', 'kath', 'kavalan', 'kay', 'kaypoh', 'kb', 'ke', 'keeping', 'keeps', 'kegger', 'keluviri', 'kent', 'kept', 'kerala', 'keralacircle', 'keris', 'kettoda', 'key', 'keypad', 'keys', 'keyword', 'kfc', 'kg', 'khelate', 'ki', 'kick', 'kickboxing', 'kickoff', 'kicks', 'kid', 'kidding', 'kids', 'kidz', 'kiefer', 'kill', 'killed', 'killing', 'kills', 'kilos', 'kind', 'kinda', 'kindly', 'king', 'kingdom', 'kintu', 'kiosk', 'kip', 'kisi', 'kiss', 'kisses', 'kissing', 'kit', 'kittum', 'kitty', 'kl341', 'knackered', 'knee', 'knew', 'knickers', 'know', 'knowing', 'known', 'knows', 'knw', 'ko', 'kochi', 'kolathupalayam', 'konw', 'korean', 'kotees', 'kothi', 'kr', 'ktv', 'kuch', 'kudi', 'kusruthi', 'kvb', 'kz', 'l8', 'l8er', 'l8r', 'l8rs', 'l8tr', 'la', 'la1', 'la3', 'la32wu', 'lab', 'labor', 'lac', 'lacking', 'lacs', 'ladies', 'lady', 'lag', 'lage', 'lager', 'laid', 'lakhs', 'lambda', 'lambu', 'lamp', 'lancaster', 'land', 'landing', 'landline', 'landlineonly', 'landlines', 'lands', 'lane', 'language', 'lanre', 'lap', 'lapdancer', 'laptop', 'lar', 'laready', 'largest', 'lark', 'lastest', 'lasting', 'late', 'lately', 'latelyxxx', 'later', 'latest', 'latests', 'latr', 'laugh', 'laughed', 'laughing', 'laughs', 'lautech', 'lavender', 'law', 'laxinorficated', 'lay', 'lays', 'lazy', 'lccltd', 'ld', 'ldew', 'ldn', 'ldnw15h', 'le', 'lead', 'leadership', 'leading', 'leads', 'leaf', 'leafcutter', 'learn', 'least5times', 'leave', 'leaves', 'leaving', 'lect', 'lecture', 'lecturer', 'left', 'leftovers', 'leg', 'legal', 'legitimat', 'legs', 'leh', 'lei', 'lekdog', 'lemme', 'lengths', 'lennon', 'leona', 'leonardo', 'les', 'lesser', 'lesson', 'lessons', 'let', 'lets', 'letter', 'letters', 'level', 'lf56', 'li', 'liao', 'lib', 'libertines', 'library', 'lido', 'lie', 'lies', 'life', 'lifeis', 'lifetime', 'lifpartnr', 'lift', 'lifted', 'lifting', 'light', 'lighters', 'lightly', 'lik', 'like', 'liked', 'likely', 'likes', 'likeyour', 'liking', 'lil', 'lily', 'lim', 'limit', 'limited', 'limiting', 'limits', 'limping', 'lindsay', 'line', 'lined', 'linerental', 'lines', 'lingo', 'link', 'linux', 'lion', 'lionm', 'lionp', 'lions', 'lip', 'lipo', 'liquor', 'list', 'listed', 'listen', 'listened2the', 'listener', 'listening', 'listening2the', 'listn', 'lists', 'literally', 'litres', 'little', 'live', 'lived', 'liver', 'liverpool', 'lives', 'living', 'lkpobox177hp51fl', 'll', 'llc', 'lmao', 'lnly', 'lo', 'load', 'loads', 'loan', 'loans', 'lobby', 'local', 'location', 'locations', 'lock', 'lodge', 'lodging', 'log', 'logged', 'login', 'logo', 'logoff', 'logon', 'logos', 'loko', 'lol', 'lolnice', 'lololo', 'london', 'loneliness', 'lonely', 'long', 'longer', 'lonlines', 'loo', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'looks', 'loooooool', 'looovvve', 'loose', 'loosing', 'lor', 'lord', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lots', 'lotsly', 'lotta', 'lotz', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovejen', 'lovely', 'loveme', 'lover', 'loverboy', 'lovers', 'loves', 'lovin', 'loving', 'lovingly', 'lovly', 'low', 'lower', 'lowes', 'loxahatchee', 'loyal', 'loyalty', 'lrg', 'ls1', 'ls15hb', 'lst', 'lt', 'ltdhelpdesk', 'lttrs', 'lubly', 'luck', 'luckily', 'lucky', 'lucozade', 'lucy', 'luks', 'lunch', 'lunchtime', 'lush', 'luv', 'luvd', 'luvs', 'lux', 'luxury', 'lv', 'lvblefrnd', 'lying', 'lyk', 'lyricalladie', 'lyrics', 'm100', 'm221bp', 'm227xy', 'm26', 'm263uz', 'm39m51', 'm60', 'm8', 'm8s', 'm95', 'ma', 'maaaan', 'maangalyam', 'mac', 'macedonia', 'macha', 'machan', 'machi', 'machines', 'macho', 'mack', 'macs', 'mad', 'madam', 'madodu', 'madoke', 'mag', 'maga', 'maggi', 'magic', 'magical', 'magicalsongs', 'mah', 'mahal', 'mahaveer', 'maid', 'mail', 'mailbox', 'mailed', 'mails', 'main', 'maintain', 'maintaining', 'make', 'makes', 'makiing', 'makin', 'making', 'malaria', 'malarky', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manchester', 'manda', 'mandan', 'mandara', 'maneesha', 'manege', 'mango', 'manky', 'manual', 'map', 'mapquest', 'maps', 'maraikara', 'marandratha', 'march', 'maretare', 'margaret', 'margin', 'marine', 'mark', 'market', 'marketing', 'marking', 'marley', 'marriage', 'married', 'marry', 'marsms', 'maruti', 'marvel', 'mary', 'mas', 'massive', 'masteriastering', 'masters', 'mat', 'match', 'matched', 'matches', 'mate', 'mates', 'math', 'mathe', 'mathematics', 'mathews', 'matra', 'matrix3', 'matter', 'matters', 'matthew', 'matured', 'maturity', 'max', 'max10mins', 'maximize', 'maximum', 'mayb', 'maybe', 'mb', 'mc', 'mca', 'mcfly', 'mcr', 'meal', 'meals', 'mean', 'meaning', 'meaningless', 'means', 'meant', 'measure', 'meat', 'meatballs', 'mecause', 'med', 'medical', 'medicine', 'meds', 'mee', 'meet', 'meetin', 'meeting', 'meetins', 'meets', 'meg', 'mega', 'meh', 'mei', 'mel', 'melle', 'melnite', 'melody', 'melt', 'member', 'members', 'membership', 'memorable', 'memories', 'memory', 'men', 'mens', 'mental', 'mention', 'mentioned', 'mentionned', 'mentor', 'menu', 'merely', 'merememberin', 'merry', 'mesages', 'mess', 'message', 'messaged', 'messages', 'messaging', 'messed', 'messenger', 'messy', 'met', 'method', 'mfl', 'mi', 'mia', 'mid', 'middle', 'midnight', 'miiiiiiissssssssss', 'mila', 'mileage', 'miles', 'milk', 'millers', 'million', 'millions', 'milta', 'min', 'mina', 'mind', 'mindset', 'minecraft', 'mini', 'minmobsmore', 'minmobsmorelkpobox177hp51fl', 'minmoremobsemspobox45po139wa', 'minnaminunginte', 'minor', 'mins', 'mint', 'minus', 'minute', 'minutes', 'minuts', 'miracle', 'mirror', 'mis', 'miserable', 'misfits', 'mising', 'miss', 'misscall', 'missed', 'missin', 'missing', 'missionary', 'mist', 'mistake', 'mistakes', 'mite', 'mitsake', 'mittelschmertz', 'miwa', 'mix', 'mj', 'mjzgroup', 'mk17', 'mk45', 'ml', 'mm', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mmsto', 'mns', 'mnth', 'mnths', 'mo', 'moan', 'mob', 'mobcudb', 'mobile', 'mobiles', 'mobilesvary', 'mobileupd8', 'mobno', 'mobs', 'mobsi', 'moby', 'mobypobox734ls27yf', 'mode', 'model', 'modl', 'module', 'mofo', 'moji', 'mojibiola', 'mokka', 'molested', 'mom', 'moment', 'moments', 'moms', 'mon', 'monday', 'mone', 'money', 'monkeespeople', 'monkey', 'monkeyaround', 'monkeys', 'mono', 'monoc', 'monos', 'monster', 'month', 'monthly', 'months', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'mornings', 'morphine', 'moseley', 'mother', 'motherfucker', 'motivate', 'motivating', 'motor', 'motorola', 'mountain', 'mountains', 'mouth', 'moved', 'moves', 'movie', 'movies', 'movietrivia', 'moving', 'mp3', 'mquiz', 'mr', 'mre', 'mrng', 'mrt', 'ms', 'msg', 'msg150p', 'msging', 'msgrcvd', 'msgrcvd18', 'msgrcvdhg', 'msgs', 'msn', 'mt', 'mtalk', 'mths', 'mtmsg', 'mtmsg18', 'mtmsgrcvd18', 'mtnl', 'mu', 'muah', 'muchand', 'mudyadhu', 'muhommad', 'multis', 'mum', 'mumbai', 'mumhas', 'mummy', 'mums', 'mumtaz', 'munsters', 'murali', 'murder', 'murdered', 'murderer', 'mus', 'mush', 'mushy', 'music', 'musicnews', 'musta', 'musthu', 'mustprovide', 'muz', 'mw', 'mwahs', 'mylife', 'mymoby', 'myparents', 'mys', 'myspace', 'mystery', 'n8', 'n9dx', 'na', 'naal', 'nachos', 'nag', 'nagar', 'nah', 'nahi', 'nails', 'naked', 'nalla', 'nalli', 'name1', 'name2', 'named', 'names', 'nammanna', 'namous', 'nan', 'nanny', 'nannys', 'nap', 'narcotics', 'nasdaq', 'naseeb', 'nasty', 'nat', 'nat27081980', 'natalie', 'natalie2k9', 'natalja', 'national', 'nationwide', 'nattil', 'natural', 'nature', 'natwest', 'naughty', 'nauseous', 'nav', 'navigate', 'nb', 'nbme', 'nd', 'ndship', 'near', 'nearby', 'nearer', 'nearly', 'necesity', 'necessarily', 'necessary', 'neck', 'necklace', 'ned', 'need', 'needed', 'needle', 'needs', 'needy', 'neekunna', 'neft', 'negative', 'neglect', 'neglet', 'neighbors', 'neighbour', 'nelson', 'neo69', 'nervous', 'neshanth', 'net', 'netcollex', 'netflix', 'nething', 'netun', 'netvision', 'network', 'networking', 'networks', 'neva', 'nevamind', 'nevering', 'neville', 'new', 'neway', 'newest', 'newport', 'newquay', 'news', 'newspapers', 'nhs', 'ni8', 'nic', 'nice', 'nichols', 'nick', 'nig', 'nigeria', 'nigh', 'night', 'nighters', 'nights', 'nigpun', 'nigro', 'nike', 'nikiyu4', 'nimbomsons', 'nimya', 'ninish', 'nino', 'nipost', 'nit', 'nite', 'nitro', 'nitros', 'nitz', 'nmde', 'no1', 'noe', 'noi', 'noice', 'noise', 'noisy', 'nok', 'nokia', 'nokia6600', 'nokia6650', 'nokias', 'noline', 'non', 'noncomittal', 'nonetheless', 'nookii', 'noon', 'nope', 'nora', 'nordstrom', 'norm', 'norm150p', 'normal', 'normally', 'north', 'northampton', 'nos', 'nose', 'note', 'notebook', 'nothin', 'notice', 'notifications', 'notified', 'notixiquating', 'nottingham', 'notxt', 'noun', 'novelty', 'november', 'now1', 'nowadays', 'noworriesloans', 'nr31', 'nt', 'nte', 'ntimate', 'ntt', 'ntwk', 'nuclear', 'nudist', 'num', 'number', 'numbers', 'nursery', 'nurungu', 'nus', 'nusstu', 'nuther', 'nver', 'nvm', 'nvq', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'nytho', 'nz', 'o2', 'o2fwd', 'obedient', 'obey', 'objection', 'oble', 'oblisingately', 'obviously', 'occupied', 'occupy', 'occur', 'occurs', 'ocean', 'oclock', 'odalebeku', 'odi', 'ofcourse', 'offc', 'offcampus', 'offdam', 'offense', 'offer', 'offering', 'offers', 'office', 'officer', 'official', 'officially', 'offline', 'ofice', 'ofsi', 'ofstuff', 'ogunrinde', 'oh', 'oic', 'oil', 'oja', 'ok', 'okay', 'okden', 'okey', 'okie', 'ola', 'olage', 'olave', 'olayiwola', 'old', 'oli', 'ollu', 'olympics', 'omg', 'omw', 'onam', 'onbus', 'oncall', 'ondu', 'ones', 'oni', 'onion', 'online', 'onluy', 'only1more', 'onum', 'onwards', 'onwords', 'ooh', 'oooh', 'ooooooh', 'oops', 'open', 'opened', 'opener', 'openin', 'opening', 'openings', 'operator', 'opinion', 'opinions', 'opponenter', 'opportunity', 'opposed', 'opps', 'opt', 'opted', 'optimistic', 'optin', 'option', 'optout', 'or2optout', 'oral', 'orange', 'oranges', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'org', 'organise', 'organizer', 'orh', 'orig', 'original', 'orno', 'ors', 'ortxt', 'oru', 'oscar', 'oso', 'otbox', 'othrs', 'othrwise', 'otside', 'ou', 'ouch', 'outages', 'outbid', 'outdoors', 'outfit', 'outfor', 'outrageous', 'outs', 'outside', 'outsider', 'outstanding', 'outta', 'oveable', 'overa', 'overdid', 'overdose', 'overemphasise', 'overheating', 'overtime', 'ovulation', 'ow', 'owed', 'owned', 'owns', 'oz', 'pa', 'paces', 'pack', 'package', 'packing', 'packs', 'padhe', 'page', 'pages', 'pai', 'paid', 'pain', 'painful', 'paining', 'pairs', 'pale', 'palm', 'panalam', 'pandy', 'panic', 'panicks', 'panren', 'pansy', 'panties', 'pants', 'pap', 'paper', 'paperwork', 'paracetamol', 'parachute', 'parade', 'paragon', 'paragraphs', 'parantella', 'parco', 'parent', 'parents', 'paris', 'park', 'parked', 'parkin', 'parking', 'participate', 'particular', 'parties', 'partner', 'partnership', 'parts', 'party', 'paru', 'pases', 'pass', 'passable', 'passed', 'passes', 'passionate', 'passport', 'password', 'passwords', 'past', 'patent', 'path', 'pathaya', 'paths', 'patients', 'patrick', 'pattern', 'patty', 'paul', 'pause', 'pavanaputra', 'pax', 'pay', 'payasam', 'payed', 'payee', 'paying', 'payment', 'payments', 'payoh', 'pc', 'pc1323', 'pdate_now', 'peaceful', 'peach', 'peak', 'pears', 'pee', 'peeps', 'pehle', 'pei', 'pen', 'pence', 'pendent', 'pending', 'penis', 'penny', 'people', 'percent', 'percentages', 'perf', 'perfect', 'performance', 'perfume', 'peril', 'period', 'peripherals', 'permission', 'persevered', 'persolvo', 'person', 'person2die', 'personal', 'personality', 'personally', 'persons', 'perumbavoor', 'pesky', 'pest', 'pete', 'petey', 'petrol', 'pg', 'ph', 'phasing', 'phb1', 'phd', 'phews', 'phil', 'philosophical', 'philosophy', 'phne', 'phoenix', 'phone', 'phonebook', 'phoned', 'phones', 'phony', 'photo', 'photos', 'php', 'phyhcmk', 'physics', 'piah', 'pic', 'pick', 'picked', 'picking', 'pics', 'picsfree1', 'picture', 'pictures', 'pie', 'piece', 'pieces', 'pierre', 'pig', 'piggy', 'pilates', 'pile', 'pimples', 'pin', 'pink', 'pints', 'pissed', 'pity', 'pix', 'pixels', 'pizza', 'pl', 'place', 'placed', 'placement', 'places', 'plaid', 'plan', 'plane', 'planet', 'planettalkinstant', 'planned', 'planning', 'plans', 'plate', 'play', 'played', 'player', 'players', 'playin', 'playing', 'playng', 'plaza', 'pleasant', 'pleased', 'pleasure', 'pleasured', 'plenty', 'plm', 'ploughing', 'pls', 'plum', 'plumbing', 'plus', 'plyr', 'plz', 'pm', 'pmt', 'po', 'po19', 'pobox', 'pobox114', 'pobox12n146tf15', 'pobox12n146tf150p', 'pobox202', 'pobox334', 'pobox36504w45wq', 'pobox365o4w45wq', 'pobox45w2tg150p', 'pobox75ldns7', 'pobox84', 'poboxox36504w45wq', 'pocked', 'pocketbabe', 'pocy', 'pod', 'poem', 'poet', 'point', 'points', 'poker', 'poking', 'pokkiri', 'pole', 'police', 'politicians', 'polo', 'poly', 'poly3', 'polyc', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'poo', 'pookie', 'poop', 'poor', 'poorly', 'poortiyagi', 'pop', 'popcorn', 'popped', 'popping', 'porn', 'porridge', 'port', 'portal', 'portege', 'portions', 'pose', 'posh', 'posible', 'position', 'positions', 'positive', 'possession', 'possessive', 'possessiveness', 'possibility', 'possible', 'possibly', 'post', 'postal', 'postcard', 'postcode', 'posted', 'postponed', 'posts', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pounded', 'pounds', 'poured', 'pours', 'pouts', 'power', 'powerful', 'poyyarikatur', 'ppl', 'pple', 'ppm', 'ppm150', 'ppt150x3', 'prabha', 'prabu', 'pract', 'practical', 'practice', 'practicing', 'praises', 'prakasam', 'prakasamanu', 'prakesh', 'praps', 'prasad', 'prasanth', 'praveesh', 'pray', 'prayers', 'praying', 'prayrs', 'pre', 'predicte', 'predicting', 'prediction', 'predictive', 'prefer', 'preferably', 'premarica', 'premier', 'premium', 'prepaid', 'prepare', 'prepared', 'prepayment', 'preponed', 'prescribed', 'prescription', 'present', 'presnts', 'press', 'pressies', 'pressure', 'prestige', 'pretend', 'pretsorginta', 'pretsovru', 'pretty', 'prevent', 'previews', 'previous', 'previously', 'prey', 'price', 'pride', 'priest', 'prince', 'princes', 'princess', 'print', 'printer', 'priscilla', 'privacy', 'private', 'priya', 'prize', 'prizeawaiting', 'prizes', 'prizeswith', 'pro', 'prob', 'probably', 'problem', 'problematic', 'problems', 'problms', 'problum', 'probpop', 'probs', 'probthat', 'process', 'processed', 'prods', 'products', 'professional', 'professors', 'profile', 'profit', 'program', 'programs', 'project', 'projects', 'prolly', 'prometazine', 'prominent', 'promise', 'promised', 'promises', 'promo', 'promoting', 'promotion', 'promptly', 'prompts', 'prone', 'proof', 'proove', 'proper', 'properly', 'property', 'propose', 'propsd', 'pros', 'prospects', 'protect', 'prove', 'proverb', 'provided', 'provider', 'province', 'prsn', 'ps', 'pshew', 'psp', 'psxtra', 'psychiatrist', 'psychic', 'psychologist', 'pt2', 'ptbo', 'pthis', 'pub', 'public', 'publish', 'pubs', 'pudunga', 'pull', 'pulling', 'pulls', 'pump', 'punch', 'punish', 'punishment', 'punj', 'punto', 'puppy', 'pura', 'purchase', 'purchases', 'pure', 'purity', 'purple', 'purpose', 'purse', 'pushbutton', 'pushes', 'pussy', 'puttin', 'putting', 'puzzeles', 'puzzles', 'px3748', 'qatar', 'qbank', 'qi', 'qing', 'quality', 'quarter', 'que', 'queen', 'queries', 'ques', 'question', 'questioned', 'questions', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'quiteamuzing', 'quitting', 'quiz', 'quizclub', 'quizzes', 'quote', 'quoting', 'r836', 'racal', 'racing', 'radiator', 'radio', 'raed', 'rael', 'raglan', 'rahul', 'raiden', 'railway', 'rain', 'raining', 'raise', 'raj', 'rajas', 'raji', 'rajini', 'rajitha', 'rajnikant', 'rakhesh', 'raksha', 'rally', 'ralphs', 'ramaduth', 'ramen', 'ran', 'random', 'randomlly', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'ranju', 'raping', 'rate', 'rates', 'ratio', 'rats', 'raviyog', 'rawring', 'rayman', 'rays', 'rcb', 'rcd', 'rct', 'rcv', 'rcvd', 'rd', 'rdy', 'reach', 'reache', 'reached', 'reaching', 'read', 'readers', 'readiness', 'reading', 'ready', 'real', 'real1', 'realise', 'realised', 'reality', 'realize', 'realized', 'realizes', 'really', 'realy', 'reason', 'reasonable', 'reasons', 'reassurance', 'reassuring', 'rebel', 'reboot', 'rebooting', 'rebtel', 'rec', 'recd', 'receipt', 'receipts', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recession', 'recharge', 'recharged', 'recieve', 'reckon', 'recognise', 'recognises', 'record', 'recorded', 'recorder', 'records', 'recovery', 'recpt', 'recreation', 'recycling', 'red', 'redeemable', 'redeemed', 'reduce', 'ree', 'ref', 'reference', 'references', 'referin', 'reffering', 'refilled', 'reflex', 'refreshed', 'refund', 'refunded', 'refused', 'reg', 'regard', 'regarding', 'regards', 'register', 'registered', 'regret', 'regretted', 'regular', 'related', 'relation', 'relationship', 'relax', 'relaxing', 'released', 'reliant', 'relieved', 'religiously', 'rem', 'remain', 'remains', 'remember', 'remembered', 'rememberi', 'remembr', 'remembrs', 'remind', 'reminded', 'reminder', 'reminding', 'reminds', 'remixed', 'removal', 'remove', 'removed', 'rencontre', 'renewing', 'rent', 'rental', 'renting', 'rentl', 'rents', 'repairs', 'repeat', 'repeating', 'replace', 'replacement', 'replacing', 'replied', 'replies', 'reply', 'replying', 'replys150', 'report', 'representative', 'republic', 'request', 'requests', 'require', 'required', 'requirements', 'requires', 'research', 'resend', 'resent', 'reserve', 'reserved', 'reserves', 'reset', 'resizing', 'reslove', 'resolution', 'resolved', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibilities', 'responsibility', 'responsible', 'rest', 'restaurant', 'restocked', 'restrict', 'restrictions', 'resubbing', 'result', 'results', 'resume', 'retard', 'retired', 'retrieve', 'return', 'returned', 'returning', 'returns', 'reunion', 'reveal', 'revealed', 'revealing', 'reverse', 'review', 'revision', 'reward', 'rewarding', 'rgds', 'rgent', 'rhode', 'rhythm', 'rice', 'rich', 'ridden', 'ride', 'right', 'rightio', 'rightly', 'rights', 'riley', 'rimac', 'ring', 'ringing', 'rings', 'ringtone', 'ringtoneking', 'ringtones', 'rinu', 'rip', 'ripped', 'risk', 'rite', 'river', 'road', 'roads', 'roast', 'rob', 'robinson', 'robs', 'rock', 'rocking', 'rocks', 'rodds1', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roomate', 'roommate', 'roommates', 'rooms', 'ros', 'rose', 'roses', 'rough', 'round', 'rounder', 'rounds', 'row', 'rowdy', 'rows', 'royal', 'rpl', 'rply', 'rs', 'rstm', 'rt', 'rtf', 'rtm', 'rto', 'ru', 'rubber', 'rude', 'rudi', 'rugby', 'ruin', 'ruining', 'rule', 'rules', 'rum', 'rummer', 'rumour', 'run', 'running', 'runs', 'rupaul', 'rush', 'ruthful', 'rv', 'rvx', 'rwm', 'ryder', 'sac', 'sachin', 'sack', 'sacked', 'sacrifice', 'sad', 'sae', 'safe', 'safety', 'sagamu', 'saibaba', 'said', 'sake', 'salam', 'salary', 'sale', 'sales', 'salesman', 'sall', 'salon', 'sam', 'samachara', 'samantha', 'sambar', 'samus', 'sandiago', 'sane', 'sang', 'sankatmochan', 'sankranti', 'santa', 'santacalling', 'sao', 'sapna', 'sar', 'sara', 'sarasota', 'sarcasm', 'sarcastic', 'saristar', 'sariyag', 'sary', 'sat', 'satanic', 'sathy', 'sathya', 'satisfied', 'satisfy', 'satthen', 'saturday', 'saucy', 'sausage', 'savamob', 'save', 'saved', 'saves', 'savings', 'saw', 'say', 'sayhey', 'sayin', 'saying', 'says', 'sayy', 'scallies', 'scared', 'scary', 'scenery', 'sch', 'schedule', 'school', 'schools', 'science', 'scold', 'scool', 'scorable', 'score', 'scores', 'scoring', 'scotch', 'scotland', 'scotsman', 'scouse', 'scraped', 'scrappy', 'scratches', 'scratching', 'scream', 'screamed', 'screaming', 'screen', 'screwd', 'scrounge', 'scrumptious', 'sculpture', 'sd', 'sday', 'sdryb8i', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secondary', 'seconds', 'secret', 'secretary', 'secrets', 'secs', 'section', 'sections', 'secure', 'secured', 'sed', 'seeds', 'seeing', 'seekers', 'seen', 'sef', 'seh', 'sehwag', 'select', 'selected', 'selection', 'self', 'selfindependence', 'selfish', 'selflessness', 'sell', 'selling', 'sells', 'semester', 'semiobscure', 'sen', 'send', 'sender', 'sending', 'sends', 'senrd', 'sense', 'senses', 'sensible', 'sensitive', 'sent', 'sentence', 'senthil', 'sentiment', 'seperated', 'sept', 'september', 'serena', 'series', 'seriously', 'served', 'server', 'service', 'services', 'serving', 'servs', 'set', 'setting', 'settings', 'settle', 'settled', 'settling', 'seven', 'seventeen', 'sex', 'sexiest', 'sextextuk', 'sexual', 'sexy', 'sexychat', 'sez', 'sf', 'sg', 'sh', 'sha', 'shag', 'shagged', 'shahjahan', 'shakara', 'shake', 'shakespeare', 'shaking', 'shall', 'shame', 'shampain', 'shangela', 'shanghai', 'shant', 'share', 'shared', 'sharing', 'shattered', 'shaved', 'shb', 'shd', 'sheet', 'sheets', 'sheffield', 'shelf', 'shelves', 'shesil', 'shexy', 'shhhhh', 'shijas', 'shijutta', 'shinco', 'shindig', 'shining', 'shiny', 'ship', 'shipped', 'shipping', 'shirt', 'shirts', 'shit', 'shite', 'shitin', 'shitinnit', 'shitload', 'shitstorm', 'shivratri', 'shld', 'shldxxxx', 'shock', 'shocking', 'shoes', 'shola', 'shoot', 'shop', 'shoppin', 'shopping', 'shore', 'short', 'shortage', 'shortbreaks', 'shortcode', 'shorter', 'shot', 'shoul', 'shoulders', 'shouldn', 'shouted', 'shouting', 'shove', 'shoving', 'shower', 'showers', 'showing', 'showr', 'shows', 'shracomorsglsuplt', 'shrek', 'shsex', 'shu', 'shudvetold', 'shuhui', 'shun', 'shut', 'shy', 'si', 'sian', 'sib', 'sic', 'sick', 'sickness', 'sighs', 'sight', 'sign', 'significance', 'significant', 'signin', 'signing', 'siguviri', 'silence', 'silent', 'silently', 'silver', 'sim', 'simonwatson5120', 'simple', 'simpler', 'simply', 'simpsons', 'simulate', 'sinco', 'sindu', 'sing', 'singapore', 'singing', 'single', 'singles', 'sink', 'sip', 'sipix', 'sir', 'sirji', 'sis', 'sister', 'sit', 'site', 'sitll', 'sitter', 'sittin', 'sitting', 'situation', 'situations', 'siva', 'size', 'sized', 'sk3', 'sk38xh', 'skateboarding', 'skilgme', 'skillgame', 'skills', 'skins', 'skint', 'skip', 'skirt', 'sky', 'skye', 'skype', 'skyped', 'skyving', 'slacking', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'sleepingwith', 'sleeps', 'sleepwell', 'sleepy', 'slept', 'slice', 'slices', 'slide', 'sliding', 'slightly', 'slip', 'slippers', 'slippery', 'slo', 'slob', 'slots', 'slovely', 'slow', 'slowly', 'slp', 'slurp', 'smacks', 'small', 'smart', 'smartcall', 'smarter', 'smash', 'smashed', 'smear', 'smells', 'smeone', 'smidgin', 'smile', 'smiled', 'smiles', 'smiley', 'smiling', 'smith', 'smoke', 'smoked', 'smokes', 'smokin', 'smoking', 'sms', 'smsco', 'smsing', 'smsrewards', 'smsservices', 'smth', 'sn', 'snake', 'snap', 'snd', 'sneham', 'snickering', 'snoring', 'snot', 'snow', 'snowball', 'snowman', 'soc', 'sochte', 'social', 'sofa', 'soft', 'software', 'soil', 'soiree', 'sol', 'soladha', 'sold', 'solve', 'solved', 'some1', 'somebody', 'someday', 'someonone', 'someplace', 'somerset', 'sometext', 'somethin', 'sometme', 'somewheresomeone', 'somtimes', 'sonathaya', 'sonetimes', 'song', 'songs', 'sony', 'sonyericsson', 'soo', 'soon', 'sooner', 'sooo', 'soooo', 'sooooo', 'sophas', 'sore', 'sorrow', 'sorrows', 'sorry', 'sort', 'sorta', 'sorted', 'sorting', 'sorts', 'sory', 'soryda', 'sos', 'soul', 'sound', 'sounding', 'sounds', 'soundtrack', 'soup', 'source', 'sources', 'south', 'southern', 'souveniers', 'soz', 'sozi', 'sp', 'space', 'spacebucks', 'spaces', 'spageddies', 'spain', 'spam', 'spanish', 'spare', 'spares', 'spark', 'sparkling', 'spatula', 'speak', 'speaking', 'special', 'speciale', 'specialisation', 'specially', 'specific', 'specify', 'specs', 'speechless', 'speed', 'speedchat', 'speeding', 'speling', 'spell', 'spelled', 'spelling', 'spend', 'spending', 'spent', 'sphosting', 'spice', 'spider', 'spiffing', 'spile', 'spin', 'spinout', 'spirit', 'spiritual', 'spjanuary', 'spk', 'spl', 'splash', 'splashmobile', 'splendid', 'split', 'splleing', 'spoilt', 'spoke', 'spoken', 'spook', 'spoon', 'spoons', 'sporadically', 'sport', 'sports', 'spot', 'spotty', 'spouse', 'spreadsheet', 'spree', 'spring', 'springs', 'sprint', 'sptv', 'spun', 'spys', 'squatting', 'squeeeeeze', 'squeezed', 'squishy', 'srs', 'srsly', 'sry', 'st', 'stable', 'staff', 'stage', 'stairs', 'stalking', 'stamped', 'stamps', 'stand', 'standard', 'standing', 'stands', 'stapati', 'star', 'staring', 'starring', 'stars', 'start', 'started', 'starting', 'starts', 'starve', 'starving', 'starwars3', 'stated', 'statement', 'statements', 'station', 'status', 'stay', 'stayed', 'stayin', 'staying', 'stays', 'std', 'stdtxtrate', 'steak', 'stealing', 'steam', 'steamboat', 'steed', 'steering', 'step', 'steps', 'stereo', 'stereophonics', 'sterling', 'sterm', 'steve', 'steyn', 'sth', 'sticky', 'stifled', 'stink', 'stitch', 'stock', 'stocked', 'stockport', 'stolen', 'stomach', 'stomps', 'stone', 'stones', 'stool', 'stop', 'stop2', 'stop2stop', 'stopbcm', 'stopcost', 'stopped', 'stops', 'stopsms', 'store', 'stores', 'storming', 'story', 'str', 'str8', 'straight', 'strain', 'stranger', 'stream', 'street', 'stress', 'stressed', 'stressfull', 'stretch', 'strict', 'strike', 'strings', 'strip', 'stripes', 'strips', 'strokes', 'strong', 'strongly', 'strt', 'strtd', 'sts', 'stu', 'stubborn', 'stuck', 'student', 'studentfinancial', 'students', 'studies', 'studio', 'study', 'studying', 'studyn', 'stuff', 'stuffing', 'stunning', 'stupid', 'style', 'styles', 'stylish', 'stylist', 'sub', 'subject', 'subletting', 'submitted', 'submitting', 'subpoly', 'subs', 'subs16', 'subscribe', 'subscriber', 'subscribers', 'subscription', 'subscriptions', 'subscriptn3gbp', 'subscrition', 'success', 'successful', 'successfully', 'sucker', 'suckers', 'sucks', 'suddenly', 'sue', 'suffer', 'suffering', 'suffers', 'sufficient', 'suganya', 'sugar', 'sugardad', 'suggest', 'suggestion', 'suggestions', 'suite', 'suite342', 'suitemates', 'suits', 'sum', 'sum1', 'suman', 'sumfing', 'summer', 'summers', 'sumthin', 'sun', 'sun0819', 'sunday', 'sundayish', 'sunlight', 'sunny', 'sunroof', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'suply', 'supose', 'suppliers', 'supplies', 'supply', 'support', 'suppose', 'supposed', 'supreme', 'suprman', 'sura', 'sure', 'surely', 'surf', 'surfing', 'surgical', 'surly', 'surprise', 'surprised', 'surrounded', 'survey', 'surya', 'sutra', 'sux', 'suzy', 'svc', 'sw7', 'sw73ss', 'swalpa', 'swan', 'swann', 'swap', 'swat', 'swatch', 'swayze', 'swear', 'sweater', 'sweet', 'sweetest', 'sweetheart', 'sweetie', 'sweets', 'swell', 'swhrt', 'swimming', 'swimsuit', 'swing', 'swiss', 'switch', 'swollen', 'swoop', 'swt', 'swtheart', 'syd', 'syllabus', 'symbol', 'sympathetic', 'synced', 'syria', 'syrup', 'systems', 't91', 'ta', 'table', 'tablets', 'tackle', 'tacos', 'tactful', 'tagged', 'tahan', 'tait', 'taj', 'taka', 'takecare', 'taken', 'takes', 'takin', 'taking', 'talent', 'talents', 'talk', 'talkbut', 'talked', 'talkin', 'talking', 'talks', 'tallahassee', 'tallent', 'tamilnadu', 'tampa', 'tank', 'tantrum', 'tap', 'tape', 'tariffs', 'tarot', 'tarpon', 'taste', 'tasts', 'tat', 'tata', 'tats', 'tau', 'taught', 'taunton', 'taxes', 'taxi', 'taxless', 'taylor', 'tayseer', 'tb', 'tbs', 'tc', 'tcr', 'tcs', 'tddnewsletter', 'tea', 'teach', 'teacher', 'teachers', 'teaches', 'teaching', 'team', 'teams', 'tear', 'tears', 'tease', 'teasing', 'tech', 'technical', 'technologies', 'tee', 'teeth', 'teju', 'tel', 'telediscount', 'telephonic', 'teletext', 'tell', 'telling', 'tellmiss', 'tells', 'telly', 'telphone', 'telugu', 'temales', 'temp', 'temper', 'temple', 'tenants', 'tendencies', 'tenerife', 'tensed', 'tension', 'teresa', 'term', 'terminated', 'terms', 'termsapply', 'ternal', 'terrible', 'terrific', 'terror', 'terrorist', 'terry', 'tescos', 'tessy', 'test', 'testing', 'tests', 'tex', 'texas', 'text', 'textand', 'textbook', 'textbuddy', 'textcomp', 'texted', 'textin', 'texting', 'textoperator', 'textpod', 'texts', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanku', 'thankyou', 'thanx', 'thanx4', 'thasa', 'that2worzels', 'thats', 'theacusations', 'theater', 'theatre', 'thedailydraw', 'theirs', 'thekingshead', 'themed', 'themes', 'themob', 'thenampet', 'theory', 'theplace', 'theres', 'thesis', 'thew', 'theyre', 'thgt', 'thia', 'thing', 'things', 'think', 'thinked', 'thinkin', 'thinking', 'thinks', 'thinkthis', 'thinl', 'thirunelvali', 'thk', 'thkin', 'thm', 'thnk', 'thnq', 'thnx', 'tho', 'thot', 'thou', 'thought', 'thoughts', 'thousands', 'thread', 'threats', 'threw', 'thriller', 'throat', 'throw', 'throwin', 'throwing', 'thrown', 'throws', 'ths', 'tht', 'thts', 'thuglyfe', 'thurs', 'thursday', 'thx', 'thy', 'tick', 'ticket', 'tickets', 'tiempo', 'tiger', 'tight', 'tihs', 'tiime', 'til', 'till', 'tim', 'time', 'times', 'timi', 'timing', 'tiny', 'tip', 'tips', 'tired', 'tirunelvai', 'tirunelvali', 'tirupur', 'tis', 'tissco', 'title', 'titles', 'tiwary', 'tiz', 'tke', 'tkts', 'tlk', 'tlp', 'tm', 'tming', 'tmorow', 'tmorrow', 'tmr', 'tmrw', 'tms', 'tnc', 'tncs', 'toa', 'tocall', 'toclaim', 'today', 'todays', 'todo', 'tog', 'toilet', 'tok', 'token', 'toking', 'tol', 'told', 'toledo', 'tolerance', 'tolerat', 'toll', 'tom', 'tomarrow', 'tomeandsaid', 'tomo', 'tomorro', 'tomorrow', 'tone', 'tones', 'tones2u', 'tones2you', 'tonght', 'tongued', 'tonight', 'tonights', 'tonite', 'tons', 'took', 'tookplace', 'tool', 'tooo', 'toot', 'tooth', 'topic', 'toplay', 'tops', 'torch', 'tortilla', 'torture', 'tosend', 'toshiba', 'toss', 'tot', 'total', 'totally', 'totes', 'touch', 'touched', 'tough', 'tour', 'town', 'toxic', 'toyota', 'track', 'trackmarque', 'trade', 'traffic', 'train', 'training', 'trainners', 'trains', 'tram', 'transaction', 'transfer', 'transfered', 'transfr', 'transfred', 'transport', 'trauma', 'trav', 'travel', 'traveling', 'travelled', 'travelling', 'treadmill', 'treasure', 'treat', 'treated', 'treats', 'trebles', 'tree', 'trek', 'trends', 'trial', 'tried', 'trip', 'trips', 'trishul', 'triumphed', 'trivia', 'tron', 'trouble', 'troubleshooting', 'trouser', 'truble', 'truck', 'true', 'true18', 'truffles', 'truly', 'truro', 'trust', 'truth', 'try', 'trying', 'ts', 'tsandcs', 'tscs', 'tscs08714740323', 'tscs087147403231winawk', 'tsunami', 'tsunamis', 'tt', 'ttyl', 'tue', 'tues', 'tuesday', 'tuition', 'tulip', 'tunde', 'tunji', 'turkeys', 'turn', 'turned', 'turning', 'turns', 'tuth', 'tv', 'twat', 'twice', 'twiggs', 'twilight', 'twinks', 'twins', 'tx', 'txt', 'txt250', 'txt43', 'txtauction', 'txtin', 'txting', 'txtno', 'txts', 'txtstar', 'txttowin', 'txtx', 'tyler', 'type', 'types', 'typical', 'tyrone', 'u2moro', 'u4', 'ubi', 'ugadi', 'ugh', 'ugo', 'uh', 'uhhhhrmm', 'uin', 'ujhhhhhhh', 'uk', 'ukp', 'uks', 'ultimate', 'ultimatum', 'um', 'umma', 'ummifying', 'ummma', 'ummmmmaah', 'unable', 'unbelievable', 'unbreakable', 'unclaimed', 'uncle', 'uncles', 'unconditionally', 'unconscious', 'unconvinced', 'uncountable', 'underdtand', 'understand', 'understanding', 'understood', 'underwear', 'undrstndng', 'unemployed', 'uneventful', 'unfolds', 'unfortunately', 'unfortuntly', 'unhappiness', 'uni', 'unicef', 'uniform', 'unintentional', 'unique', 'united', 'units', 'university', 'unjalur', 'unkempt', 'unknown', 'unless', 'unlike', 'unlimited', 'unmits', 'unnecessarily', 'unni', 'unredeemed', 'unsecured', 'unsold', 'unsub', 'unsubscribe', 'unsubscribed', 'untamed', 'up4', 'upcharge', 'upd8', 'updat', 'update', 'update_now', 'upgrade', 'upgrading', 'upload', 'uploaded', 'upping', 'ups', 'upset', 'upstairs', 'upto', 'uptown', 'ur', 'urawinner', 'ure', 'urfeeling', 'urgent', 'urgently', 'urgh', 'urgnt', 'urgran', 'urination', 'url', 'urmom', 'urn', 'urself', 'usa', 'usc', 'use', 'used', 'useful', 'user', 'uses', 'usf', 'usher', 'using', 'usmle', 'usps', 'usual', 'usually', 'uterus', 'utter', 'uup', 'uve', 'uwant', 'uworld', 'va', 'vaazhthukkal', 'vague', 'vaguely', 'vale', 'valentine', 'valentines', 'valid', 'valid12hrs', 'valuable', 'value', 'valued', 'various', 'varma', 'varunnathu', 'vary', 'vat', 'vatian', 'vava', 'vday', 've', 'vegetables', 'veggie', 'vehicle', 'velachery', 'velusamy', 'venaam', 'venugopal', 'verified', 'verify', 'verifying', 'version', 'vettam', 'vewy', 'vibrator', 'vic', 'victoria', 'vid', 'video', 'videochat', 'videophones', 'videos', 'videosound', 'videosounds', 'view', 'vijay', 'vijaykanth', 'vikky', 'villa', 'village', 'vinobanagar', 'violated', 'violence', 'violet', 'vip', 'vipclub4u', 'virgil', 'virgin', 'virgins', 'virtual', 'visa', 'visionsms', 'visit', 'visitor', 'visitors', 'vital', 'vitamin', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomitin', 'vote', 'voted', 'voucher', 'vouchers', 'vry', 'vs', 'vth', 'vu', 'w1', 'w111wx', 'w1a', 'w1j', 'w1j6hl', 'w1jhl', 'w1t1jy', 'w4', 'w45wq', 'w8in', 'wa', 'wa14', 'waaaat', 'wah', 'wahala', 'wahay', 'waheed', 'waheeda', 'wahleykkum', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wales', 'waliking', 'walk', 'walkabout', 'walkin', 'walking', 'walks', 'wallet', 'wallpaper', 'walls', 'walmart', 'walsall', 'wamma', 'wan', 'wan2', 'wana', 'wanna', 'wannatell', 'want', 'want2come', 'wanted', 'wanting', 'wants', 'wap', 'waqt', 'warm', 'warming', 'warned', 'warner', 'warning', 'warranty', 'wasn', 'wasnt', 'waste', 'wasted', 'wasting', 'wat', 'watch', 'watched', 'watches', 'watching', 'watchng', 'water', 'watever', 'watevr', 'wating', 'watr', 'wats', 'watts', 'wave', 'wavering', 'way', 'way2sms', 'waz', 'wc1n', 'wc1n3xx', 'weak', 'weakness', 'weaknesses', 'weapon', 'wear', 'wearing', 'weaseling', 'weasels', 'weather', 'web', 'web2mobile', 'webadres', 'webeburnin', 'webpage', 'website', 'wed', 'weddin', 'wedding', 'wednesday', 'weds', 'wee', 'weed', 'week', 'weekdays', 'weekend', 'weekends', 'weekly', 'weeks', 'weigh', 'weighed', 'weight', 'weird', 'weirdest', 'weirdy', 'weiyi', 'welcome', 'welcomes', 'wellda', 'welp', 'wen', 'wendy', 'wenever', 'went', 'wenwecan', 'wer', 'werebored', 'weren', 'werethe', 'west', 'western', 'westlife', 'westonzoyland', 'westshore', 'wet', 'wewa', 'whassup', 'whats', 'whatsup', 'wheat', 'whenevr', 'whens', 'whereare', 'wherevr', 'wherre', 'whilltake', 'white', 'whn', 'whore', 'whos', 'whr', 'wi', 'wicked', 'wicket', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifes', 'wifi', 'wihtuot', 'wikipedia', 'wil', 'wild', 'wildest', 'wildlife', 'willing', 'willpower', 'win', 'win150ppmx3age16', 'wind', 'window', 'windows', 'winds', 'wine', 'wings', 'winner', 'winnersclub', 'winning', 'wins', 'wipro', 'wire3', 'wisdom', 'wise', 'wish', 'wisheds', 'wishes', 'wishin', 'wishing', 'wishlist', 'wiskey', 'wit', 'withdraw', 'witin', 'witout', 'wiv', 'wizzle', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wlcome', 'wld', 'wml', 'wn', 'wnevr', 'wnt', 'wo', 'woke', 'woken', 'woman', 'women', 'won', 'wondar', 'wonder', 'wonderful', 'wondering', 'wonders', 'wont', 'woo', 'woods', 'woohoo', 'woot', 'woould', 'woozles', 'word', 'words', 'work', 'workage', 'workand', 'workin', 'working', 'workout', 'works', 'world', 'worried', 'worries', 'worry', 'worrying', 'worse', 'worst', 'worth', 'worthless', 'wot', 'wotu', 'wotz', 'woulda', 'wouldn', 'wow', 'wrc', 'wrenching', 'wright', 'write', 'wrk', 'wrkin', 'wrks', 'wrld', 'wrnog', 'wrong', 'wrongly', 'wrote', 'ws', 'wt', 'wtc', 'wtf', 'wth', 'wthout', 'wtlp', 'wud', 'wudn', 'wuld', 'wuldnt', 'wun', 'www', 'wylie', 'x2', 'x49', 'xafter', 'xam', 'xavier', 'xchat', 'xclusive', 'xin', 'xmas', 'xoxo', 'xuhui', 'xx', 'xxsp', 'xxuk', 'xxx', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxx', 'xxxxxxxxxxxxxx', 'xy', 'y87', 'ya', 'yah', 'yahoo', 'yam', 'yan', 'yar', 'yarasu', 'yards', 'yaxx', 'yaxxx', 'yay', 'yck', 'yeah', 'year', 'years', 'yeesh', 'yeh', 'yelling', 'yellow', 'yelow', 'yen', 'yeovil', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetty', 'yetunde', 'yhl', 'yi', 'yifeng', 'yijue', 'ym', 'ymca', 'yo', 'yoga', 'yogasana', 'yor', 'youdoing', 'youi', 'youphone', 'youre', 'yourinclusive', 'youwanna', 'yoville', 'yowifes', 'yr', 'yrs', 'ystrday', 'yummmm', 'yummy', 'yun', 'yunny', 'yuo', 'yuou', 'yup', 'yupz', 'zac', 'zaher', 'zealand', 'zed', 'zeros', 'zhong', 'zindgi', 'zoe', 'zogtorius', 'zoom', 'zouk', 'zyada', 'èn', 'ú1', '〨ud']\n",
      "7260\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names())\n",
    "print(len(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the train and test data sets\n",
    "x_train_transformed = vect.transform(x_train)\n",
    "x_test_transformed = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 3078)\t1\n",
      "  (0, 3879)\t1\n",
      "  (0, 3927)\t1\n",
      "  (0, 4013)\t1\n",
      "  (0, 4368)\t1\n",
      "  (0, 5630)\t1\n",
      "  (1, 1985)\t1\n",
      "  (1, 2993)\t1\n",
      "  (1, 3179)\t1\n",
      "  (1, 3719)\t1\n",
      "  (1, 3736)\t1\n",
      "  (1, 4158)\t1\n",
      "  (1, 4503)\t2\n",
      "  (1, 4652)\t1\n",
      "  (1, 5856)\t1\n",
      "  (1, 6271)\t1\n",
      "  (2, 4950)\t1\n",
      "  (3, 1465)\t1\n",
      "  (3, 2931)\t1\n",
      "  (4, 1015)\t1\n",
      "  (4, 1683)\t1\n",
      "  (4, 3148)\t1\n",
      "  (4, 3654)\t1\n",
      "  (4, 6245)\t1\n",
      "  (5, 1040)\t1\n",
      "  :\t:\n",
      "  (4176, 675)\t2\n",
      "  (4176, 684)\t1\n",
      "  (4176, 771)\t2\n",
      "  (4176, 2218)\t1\n",
      "  (4176, 2718)\t1\n",
      "  (4176, 2940)\t1\n",
      "  (4176, 3894)\t1\n",
      "  (4176, 4243)\t1\n",
      "  (4176, 4573)\t1\n",
      "  (4176, 4822)\t1\n",
      "  (4176, 5057)\t1\n",
      "  (4176, 6369)\t1\n",
      "  (4176, 6695)\t1\n",
      "  (4176, 7162)\t1\n",
      "  (4177, 1153)\t1\n",
      "  (4177, 4628)\t1\n",
      "  (4178, 924)\t1\n",
      "  (4178, 1953)\t1\n",
      "  (4178, 3736)\t1\n",
      "  (4178, 3830)\t1\n",
      "  (4178, 3854)\t1\n",
      "  (4178, 3927)\t1\n",
      "  (4178, 4244)\t1\n",
      "  (4178, 4368)\t1\n",
      "  (4178, 7199)\t1\n"
     ]
    }
   ],
   "source": [
    "# note that the type is transformed matrix\n",
    "print(type(x_train_transformed))\n",
    "print(x_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the mnb and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the training data\n",
    "mnb.fit(x_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict class\n",
    "y_pred_class = mnb.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred_proba = mnb.predict_proba(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the overall accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827709978463748"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "k = metrics.confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1208,    8],\n",
       "       [  16,  161]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1208    8]\n",
      " [  16  161]]\n"
     ]
    }
   ],
   "source": [
    "confusion = k\n",
    "print(confusion) # [row,column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = confusion[0,0] # true negative\n",
    "FP = confusion[0,1] # false positive\n",
    "FN = confusion[1,0]\n",
    "TP = confusion[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitivity = TP / FN + TP\n",
    "\n",
    "sensitivity = TP/float(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity :  0.9526627218934911\n"
     ]
    }
   ],
   "source": [
    "print(\"sensitivity : \",sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specificity = TP/ TN+FP\n",
    "specificity  = TP/float(FN+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity is :  6.708333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"specificity is : \",specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP/float(TP+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision is :  0.9526627218934911\n"
     ]
    }
   ],
   "source": [
    "print(\"precision is : \",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9526627218934911\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9096045197740112\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306358381502889\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.73178576e-10, 9.99999999e-01],\n",
       "       [9.99997247e-01, 2.75276119e-06],\n",
       "       [9.99990879e-01, 9.12147591e-06],\n",
       "       ...,\n",
       "       [9.86349975e-01, 1.36500248e-02],\n",
       "       [9.99999993e-01, 6.59980242e-09],\n",
       "       [9.98618475e-01, 1.38152521e-03]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  *** creating an ROC curve ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as scm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positiverate , true_positive_rate,thresholds = roc_curve(y_test,y_pred_proba[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc  = auc(false_positiverate , true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false_positive_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-843c1e509282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'false_positive_rate' is not defined"
     ]
    }
   ],
   "source": [
    "roc_auc = auc(false_positive_rate, true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98088341882248\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.24293785 0.27683616 0.28248588 0.30508475 0.33333333\n",
      " 0.43502825 0.44632768 0.47457627 0.48587571 0.55367232 0.56497175\n",
      " 0.81920904 0.84180791 0.87570621 0.87570621 0.88700565 0.88700565\n",
      " 0.89830508 0.89830508 0.9039548  0.9039548  0.90960452 0.90960452\n",
      " 0.90960452 0.92090395 0.92090395 0.92655367 0.92655367 0.93220339\n",
      " 0.93220339 0.93785311 0.93785311 0.93785311 0.94350282 0.94350282\n",
      " 0.94915254 0.94915254 0.94915254 0.94915254 0.94915254 0.94915254\n",
      " 0.94915254 0.94915254 0.94915254 0.94915254 0.94915254 0.94915254\n",
      " 0.94915254 0.94915254 0.94915254 0.94915254 0.95480226 0.95480226\n",
      " 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226\n",
      " 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226\n",
      " 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226\n",
      " 0.95480226 0.95480226 0.95480226 0.95480226 0.95480226 0.96045198\n",
      " 0.96045198 0.96045198 0.96045198 0.96045198 0.96045198 0.96610169\n",
      " 0.96610169 0.96610169 0.96610169 0.96610169 0.96610169 0.96610169\n",
      " 0.96610169 0.97175141 0.97175141 0.97175141 0.97175141 0.97175141\n",
      " 0.97175141 0.97175141 0.97175141 0.97740113 0.97740113 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085\n",
      " 0.98305085 0.98305085 0.98305085 0.98305085 0.98305085 0.98870056\n",
      " 0.98870056 0.98870056 0.98870056 0.99435028 0.99435028 0.99435028\n",
      " 0.99435028 0.99435028 0.99435028 0.99435028 0.99435028 0.99435028\n",
      " 0.99435028 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(true_positive_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.22368421e-04\n",
      " 8.22368421e-04 1.64473684e-03 1.64473684e-03 3.28947368e-03\n",
      " 3.28947368e-03 4.93421053e-03 4.93421053e-03 6.57894737e-03\n",
      " 9.04605263e-03 9.04605263e-03 9.86842105e-03 9.86842105e-03\n",
      " 1.23355263e-02 1.23355263e-02 2.13815789e-02 3.37171053e-02\n",
      " 3.86513158e-02 3.94736842e-02 3.94736842e-02 4.68750000e-02\n",
      " 4.68750000e-02 4.85197368e-02 5.01644737e-02 5.26315789e-02\n",
      " 5.42763158e-02 5.92105263e-02 6.08552632e-02 6.49671053e-02\n",
      " 6.66118421e-02 6.74342105e-02 6.90789474e-02 7.23684211e-02\n",
      " 7.56578947e-02 8.22368421e-02 8.47039474e-02 9.78618421e-02\n",
      " 9.78618421e-02 1.00328947e-01 1.01973684e-01 1.03618421e-01\n",
      " 1.05263158e-01 1.11842105e-01 1.14309211e-01 1.25000000e-01\n",
      " 1.26644737e-01 1.27467105e-01 1.29111842e-01 1.32401316e-01\n",
      " 1.34046053e-01 1.35690789e-01 1.37335526e-01 1.39802632e-01\n",
      " 1.40625000e-01 1.42269737e-01 1.43092105e-01 1.44736842e-01\n",
      " 1.47203947e-01 1.48848684e-01 1.52960526e-01 1.55427632e-01\n",
      " 1.56250000e-01 1.56250000e-01 1.63651316e-01 1.65296053e-01\n",
      " 1.66940789e-01 1.68585526e-01 1.70230263e-01 1.70230263e-01\n",
      " 1.79276316e-01 1.81743421e-01 1.84210526e-01 1.85855263e-01\n",
      " 1.95723684e-01 1.97368421e-01 2.02302632e-01 2.02302632e-01\n",
      " 2.39309211e-01 2.40953947e-01 2.45065789e-01 2.47532895e-01\n",
      " 2.57401316e-01 2.59046053e-01 2.89473684e-01 2.89473684e-01\n",
      " 3.23190789e-01 3.23190789e-01 3.42105263e-01 3.43750000e-01\n",
      " 4.16940789e-01 4.19407895e-01 4.27631579e-01 4.29276316e-01\n",
      " 4.58059211e-01 4.59703947e-01 5.13980263e-01 5.15625000e-01\n",
      " 5.41118421e-01 5.41118421e-01 5.41940789e-01 5.43585526e-01\n",
      " 6.11842105e-01 6.11842105e-01 6.22532895e-01 6.24177632e-01\n",
      " 6.90789474e-01 6.99013158e-01 7.49177632e-01 7.50822368e-01\n",
      " 7.94407895e-01 7.96052632e-01 8.24013158e-01 8.24013158e-01\n",
      " 8.60197368e-01 8.61842105e-01 8.64309211e-01 8.65953947e-01\n",
      " 8.69243421e-01 8.70888158e-01 8.87335526e-01 8.88980263e-01\n",
      " 9.30921053e-01 9.32565789e-01 9.70394737e-01 9.72861842e-01\n",
      " 9.74506579e-01 9.76973684e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(false_positiverate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999999e-01 9.99999996e-01\n",
      " 9.99440079e-01 9.97974176e-01 9.42819484e-01 9.31975275e-01\n",
      " 9.12284704e-01 8.62209246e-01 7.62478611e-01 6.97653083e-01\n",
      " 6.91041520e-01 5.37857704e-01 5.37598111e-01 5.10099212e-01\n",
      " 4.16436332e-01 3.61923721e-01 3.54464971e-01 3.44562928e-01\n",
      " 3.15042335e-01 3.04823728e-01 1.37869126e-01 1.36396267e-01\n",
      " 1.35833723e-01 1.35273136e-01 1.34962189e-01 1.11227734e-01\n",
      " 1.02748055e-01 1.01529858e-01 9.67771386e-02 9.48504452e-02\n",
      " 9.44405122e-02 8.40974324e-02 8.24199078e-02 7.28656692e-02\n",
      " 7.25431369e-02 7.21261471e-02 6.69771758e-02 6.18747407e-02\n",
      " 5.91546033e-02 5.10295864e-02 4.97863514e-02 3.98618440e-02\n",
      " 3.80094328e-02 3.60863460e-02 3.55013842e-02 3.40945748e-02\n",
      " 3.37510142e-02 3.00143558e-02 2.89348783e-02 2.59177559e-02\n",
      " 2.55286652e-02 2.54099226e-02 2.54099226e-02 2.36112883e-02\n",
      " 2.35779128e-02 2.33662365e-02 2.26505477e-02 2.19618067e-02\n",
      " 2.17487717e-02 2.16556363e-02 2.12468899e-02 2.12205735e-02\n",
      " 2.04317720e-02 2.04166439e-02 1.93386871e-02 1.92694800e-02\n",
      " 1.91792780e-02 1.86139525e-02 1.77301066e-02 1.75642143e-02\n",
      " 1.70846550e-02 1.70846550e-02 1.69247206e-02 1.62110810e-02\n",
      " 1.45793143e-02 1.44111163e-02 1.36885095e-02 1.36500248e-02\n",
      " 1.23512069e-02 1.19466824e-02 1.12350884e-02 1.11607830e-02\n",
      " 6.22145059e-03 6.12634274e-03 5.98072817e-03 5.86900243e-03\n",
      " 5.17614873e-03 5.12717357e-03 3.19049456e-03 3.17487812e-03\n",
      " 2.09654285e-03 1.99161804e-03 1.52351720e-03 1.47290672e-03\n",
      " 5.73540803e-04 5.67191068e-04 5.12219117e-04 5.07515002e-04\n",
      " 3.14343830e-04 3.14026908e-04 1.57394761e-04 1.51628877e-04\n",
      " 9.65846518e-05 9.48908492e-05 9.10843403e-05 9.06658573e-05\n",
      " 2.96363229e-05 2.93740875e-05 2.69837518e-05 2.65079052e-05\n",
      " 5.32271376e-06 5.18189366e-06 1.15280443e-06 1.14452685e-06\n",
      " 3.48250494e-07 3.43812494e-07 1.00356295e-07 1.00195973e-07\n",
      " 2.15587057e-08 2.12796039e-08 1.82739108e-08 1.66235898e-08\n",
      " 1.61903482e-08 1.39490459e-08 7.02425802e-09 6.59980242e-09\n",
      " 2.91554794e-10 2.71977884e-10 3.84404282e-13 2.09295995e-13\n",
      " 1.33212347e-13 1.28442882e-13 3.13800812e-31]\n"
     ]
    }
   ],
   "source": [
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.242938</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.282486</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.435028</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.446328</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.485876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.553672</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.564972</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.994401e-01</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9.979742e-01</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.428195e-01</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.319753e-01</td>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.122847e-01</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.622092e-01</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.624786e-01</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.976531e-01</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.910415e-01</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.378577e-01</td>\n",
       "      <td>0.903955</td>\n",
       "      <td>0.004934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.375981e-01</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.004934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.100992e-01</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.006579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.164363e-01</td>\n",
       "      <td>0.909605</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.619237e-01</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.544650e-01</td>\n",
       "      <td>0.920904</td>\n",
       "      <td>0.009868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.445629e-01</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.009868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.150423e-01</td>\n",
       "      <td>0.926554</td>\n",
       "      <td>0.012336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.048237e-01</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.012336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>9.489085e-05</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.541118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>9.108434e-05</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.541941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>9.066586e-05</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.543586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2.963632e-05</td>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.611842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2.937409e-05</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.611842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2.698375e-05</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.622533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2.650791e-05</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.624178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>5.322714e-06</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.690789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.181894e-06</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.699013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.152804e-06</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.749178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.144527e-06</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.750822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.482505e-07</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.794408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3.438125e-07</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.796053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.003563e-07</td>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.824013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.001960e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2.155871e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2.127960e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.827391e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.662359e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1.619035e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.394905e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7.024258e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.599802e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2.915548e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.719779e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3.844043e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2.092960e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.332123e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.284429e-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3.138008e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        threshold       TPR       FPR\n",
       "0    2.000000e+00  0.000000  0.000000\n",
       "1    1.000000e+00  0.242938  0.000000\n",
       "2    1.000000e+00  0.276836  0.000000\n",
       "3    1.000000e+00  0.282486  0.000000\n",
       "4    1.000000e+00  0.305085  0.000000\n",
       "5    1.000000e+00  0.333333  0.000000\n",
       "6    1.000000e+00  0.435028  0.000000\n",
       "7    1.000000e+00  0.446328  0.000000\n",
       "8    1.000000e+00  0.474576  0.000000\n",
       "9    1.000000e+00  0.485876  0.000000\n",
       "10   1.000000e+00  0.553672  0.000000\n",
       "11   1.000000e+00  0.564972  0.000000\n",
       "12   9.994401e-01  0.819209  0.000000\n",
       "13   9.979742e-01  0.841808  0.000000\n",
       "14   9.428195e-01  0.875706  0.000000\n",
       "15   9.319753e-01  0.875706  0.000822\n",
       "16   9.122847e-01  0.887006  0.000822\n",
       "17   8.622092e-01  0.887006  0.001645\n",
       "18   7.624786e-01  0.898305  0.001645\n",
       "19   6.976531e-01  0.898305  0.003289\n",
       "20   6.910415e-01  0.903955  0.003289\n",
       "21   5.378577e-01  0.903955  0.004934\n",
       "22   5.375981e-01  0.909605  0.004934\n",
       "23   5.100992e-01  0.909605  0.006579\n",
       "24   4.164363e-01  0.909605  0.009046\n",
       "25   3.619237e-01  0.920904  0.009046\n",
       "26   3.544650e-01  0.920904  0.009868\n",
       "27   3.445629e-01  0.926554  0.009868\n",
       "28   3.150423e-01  0.926554  0.012336\n",
       "29   3.048237e-01  0.932203  0.012336\n",
       "..            ...       ...       ...\n",
       "113  9.489085e-05  0.988701  0.541118\n",
       "114  9.108434e-05  0.988701  0.541941\n",
       "115  9.066586e-05  0.988701  0.543586\n",
       "116  2.963632e-05  0.988701  0.611842\n",
       "117  2.937409e-05  0.994350  0.611842\n",
       "118  2.698375e-05  0.994350  0.622533\n",
       "119  2.650791e-05  0.994350  0.624178\n",
       "120  5.322714e-06  0.994350  0.690789\n",
       "121  5.181894e-06  0.994350  0.699013\n",
       "122  1.152804e-06  0.994350  0.749178\n",
       "123  1.144527e-06  0.994350  0.750822\n",
       "124  3.482505e-07  0.994350  0.794408\n",
       "125  3.438125e-07  0.994350  0.796053\n",
       "126  1.003563e-07  0.994350  0.824013\n",
       "127  1.001960e-07  1.000000  0.824013\n",
       "128  2.155871e-08  1.000000  0.860197\n",
       "129  2.127960e-08  1.000000  0.861842\n",
       "130  1.827391e-08  1.000000  0.864309\n",
       "131  1.662359e-08  1.000000  0.865954\n",
       "132  1.619035e-08  1.000000  0.869243\n",
       "133  1.394905e-08  1.000000  0.870888\n",
       "134  7.024258e-09  1.000000  0.887336\n",
       "135  6.599802e-09  1.000000  0.888980\n",
       "136  2.915548e-10  1.000000  0.930921\n",
       "137  2.719779e-10  1.000000  0.932566\n",
       "138  3.844043e-13  1.000000  0.970395\n",
       "139  2.092960e-13  1.000000  0.972862\n",
       "140  1.332123e-13  1.000000  0.974507\n",
       "141  1.284429e-13  1.000000  0.976974\n",
       "142  3.138008e-31  1.000000  1.000000\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix of thresholds , tpr ,fpr\n",
    "pd.DataFrame({'threshold': thresholds,\n",
    "               'TPR' : true_positive_rate,\n",
    "               'FPR' : false_positiverate\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('TRue positive rate')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.title('RoC')\n",
    "plt.plot(false_positiverate , true_positive_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * ** LOGISTIC REGRESSION ** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all data sets\n",
    "churn_data = pd.read_csv(\"/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/17. Logistic Regression/1.1 LogisticReg.zip/LogisticReg/churn_data.csv\")\n",
    "customer_data = pd.read_csv('/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/17. Logistic Regression/1.1 LogisticReg.zip/LogisticReg/customer_data.csv')\n",
    "internet_data = pd.read_csv(\"/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/17. Logistic Regression/1.1 LogisticReg.zip/LogisticReg/internet_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 9 columns):\n",
      "customerID          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 495.3+ KB\n"
     ]
    }
   ],
   "source": [
    "churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 5 columns):\n",
      "customerID       7043 non-null object\n",
      "gender           7043 non-null object\n",
      "SeniorCitizen    7043 non-null int64\n",
      "Partner          7043 non-null object\n",
      "Dependents       7043 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 275.2+ KB\n"
     ]
    }
   ],
   "source": [
    "customer_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 9 columns):\n",
      "customerID          7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 495.3+ KB\n"
     ]
    }
   ],
   "source": [
    "internet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging on customer id\n",
    "df1 = pd.merge(churn_data,customer_data , how = 'inner',on='customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe with all predictor values\n",
    "df2 = pd.merge(df1,internet_data,how = \"inner\",on='customerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      "customerID          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null object\n",
      "Dependents          7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>...</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  tenure PhoneService        Contract PaperlessBilling  \\\n",
       "0  7590-VHVEG       1           No  Month-to-month              Yes   \n",
       "1  5575-GNVDE      34          Yes        One year               No   \n",
       "2  3668-QPYBK       2          Yes  Month-to-month              Yes   \n",
       "3  7795-CFOCW      45           No        One year               No   \n",
       "4  9237-HQITU       2          Yes  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges TotalCharges Churn  gender  \\\n",
       "0           Electronic check           29.85        29.85    No  Female   \n",
       "1               Mailed check           56.95       1889.5    No    Male   \n",
       "2               Mailed check           53.85       108.15   Yes    Male   \n",
       "3  Bank transfer (automatic)           42.30      1840.75    No    Male   \n",
       "4           Electronic check           70.70       151.65   Yes  Female   \n",
       "\n",
       "        ...        Partner Dependents     MultipleLines InternetService  \\\n",
       "0       ...            Yes         No  No phone service             DSL   \n",
       "1       ...             No         No                No             DSL   \n",
       "2       ...             No         No                No             DSL   \n",
       "3       ...             No         No  No phone service             DSL   \n",
       "4       ...             No         No                No     Fiber optic   \n",
       "\n",
       "  OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV  \\\n",
       "0             No          Yes               No          No          No   \n",
       "1            Yes           No              Yes          No          No   \n",
       "2            Yes          Yes               No          No          No   \n",
       "3            Yes           No              Yes         Yes          No   \n",
       "4             No           No               No          No          No   \n",
       "\n",
       "  StreamingMovies  \n",
       "0              No  \n",
       "1              No  \n",
       "2              No  \n",
       "3              No  \n",
       "4              No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.371149</td>\n",
       "      <td>64.761692</td>\n",
       "      <td>0.162147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.559481</td>\n",
       "      <td>30.090047</td>\n",
       "      <td>0.368612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tenure  MonthlyCharges  SeniorCitizen\n",
       "count  7043.000000     7043.000000    7043.000000\n",
       "mean     32.371149       64.761692       0.162147\n",
       "std      24.559481       30.090047       0.368612\n",
       "min       0.000000       18.250000       0.000000\n",
       "25%       9.000000       35.500000       0.000000\n",
       "50%      29.000000       70.350000       0.000000\n",
       "75%      55.000000       89.850000       0.000000\n",
       "max      72.000000      118.750000       1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['PhoneService']=df2['PhoneService'].map({'Yes': 1,'No':0})\n",
    "df2['PaperlessBilling']=df2['PaperlessBilling'].map({'Yes': 1,'No':0})\n",
    "df2['Churn'] = df2['Churn'].map({'Yes':1,'N0':0})\n",
    "df2['Partner'] = df2['Partner'].map({'Yes':1,'No':0})\n",
    "df2['Dependents']= df2[\"Dependents\"].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      "customerID          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null int64\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null int64\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               1869 non-null float64\n",
      "gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null int64\n",
      "Dependents          7043 non-null int64\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "dtypes: float64(2), int64(6), object(13)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Churn\"].fillna(df2[\"Churn\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7b2cffe358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbn.heatmap(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.get_dummies(df2[\"gender\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-2090e30cf1fe>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-2090e30cf1fe>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    we will build a  linear SVM classifier to classify emails into spam and ham.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "we will build a  linear SVM classifier to classify emails into spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = pd.read_csv('/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/18. Support Vector Machine (SVM)/1.1 SVM.zip/SVM/Spam.txt',sep = ',',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emil.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "email.columns  = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \n",
    "                      \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \n",
    "                      \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \n",
    "                      \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \n",
    "                      \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \n",
    "                      \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "                      \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \n",
    "                      \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \n",
    "                      \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\",\n",
    "                      \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \n",
    "                      \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \n",
    "                      \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_hash\", \"capital_run_length_average\", \n",
    "                      \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      "word_freq_make                4601 non-null float64\n",
      "word_freq_address             4601 non-null float64\n",
      "word_freq_all                 4601 non-null float64\n",
      "word_freq_3d                  4601 non-null float64\n",
      "word_freq_our                 4601 non-null float64\n",
      "word_freq_over                4601 non-null float64\n",
      "word_freq_remove              4601 non-null float64\n",
      "word_freq_internet            4601 non-null float64\n",
      "word_freq_order               4601 non-null float64\n",
      "word_freq_mail                4601 non-null float64\n",
      "word_freq_receive             4601 non-null float64\n",
      "word_freq_will                4601 non-null float64\n",
      "word_freq_people              4601 non-null float64\n",
      "word_freq_report              4601 non-null float64\n",
      "word_freq_addresses           4601 non-null float64\n",
      "word_freq_free                4601 non-null float64\n",
      "word_freq_business            4601 non-null float64\n",
      "word_freq_email               4601 non-null float64\n",
      "word_freq_you                 4601 non-null float64\n",
      "word_freq_credit              4601 non-null float64\n",
      "word_freq_your                4601 non-null float64\n",
      "word_freq_font                4601 non-null float64\n",
      "word_freq_000                 4601 non-null float64\n",
      "word_freq_money               4601 non-null float64\n",
      "word_freq_hp                  4601 non-null float64\n",
      "word_freq_hpl                 4601 non-null float64\n",
      "word_freq_george              4601 non-null float64\n",
      "word_freq_650                 4601 non-null float64\n",
      "word_freq_lab                 4601 non-null float64\n",
      "word_freq_labs                4601 non-null float64\n",
      "word_freq_telnet              4601 non-null float64\n",
      "word_freq_857                 4601 non-null float64\n",
      "word_freq_data                4601 non-null float64\n",
      "word_freq_415                 4601 non-null float64\n",
      "word_freq_85                  4601 non-null float64\n",
      "word_freq_technology          4601 non-null float64\n",
      "word_freq_1999                4601 non-null float64\n",
      "word_freq_parts               4601 non-null float64\n",
      "word_freq_pm                  4601 non-null float64\n",
      "word_freq_direct              4601 non-null float64\n",
      "word_freq_cs                  4601 non-null float64\n",
      "word_freq_meeting             4601 non-null float64\n",
      "word_freq_original            4601 non-null float64\n",
      "word_freq_project             4601 non-null float64\n",
      "word_freq_re                  4601 non-null float64\n",
      "word_freq_edu                 4601 non-null float64\n",
      "word_freq_table               4601 non-null float64\n",
      "word_freq_conference          4601 non-null float64\n",
      "char_freq_;                   4601 non-null float64\n",
      "char_freq_(                   4601 non-null float64\n",
      "char_freq_[                   4601 non-null float64\n",
      "char_freq_!                   4601 non-null float64\n",
      "char_freq_$                   4601 non-null float64\n",
      "char_freq_hash                4601 non-null float64\n",
      "capital_run_length_average    4601 non-null float64\n",
      "capital_run_length_longest    4601 non-null int64\n",
      "capital_run_length_total      4601 non-null int64\n",
      "spam                          4601 non-null int64\n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "email.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...   char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...          0.00        0.000   \n",
       "1             0.00            0.94  ...          0.00        0.132   \n",
       "2             0.64            0.25  ...          0.01        0.143   \n",
       "3             0.31            0.63  ...          0.00        0.137   \n",
       "4             0.31            0.63  ...          0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "0          0.0        0.778        0.000           0.000   \n",
       "1          0.0        0.372        0.180           0.048   \n",
       "2          0.0        0.276        0.184           0.010   \n",
       "3          0.0        0.137        0.000           0.000   \n",
       "4          0.0        0.135        0.000           0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
       "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
       "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
       "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
       "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "count  4601.000000  4601.000000  4601.000000     4601.000000   \n",
       "mean      0.016976     0.269071     0.075811        0.044238   \n",
       "std       0.109394     0.815672     0.245882        0.429342   \n",
       "min       0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.315000     0.052000        0.000000   \n",
       "max       4.081000    32.478000     6.003000       19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                    481.050\n",
       "word_freq_address                 980.080\n",
       "word_freq_all                    1291.300\n",
       "word_freq_3d                      301.020\n",
       "word_freq_our                    1436.540\n",
       "word_freq_over                    441.240\n",
       "word_freq_remove                  525.470\n",
       "word_freq_internet                484.460\n",
       "word_freq_order                   414.400\n",
       "word_freq_mail                   1101.540\n",
       "word_freq_receive                 275.250\n",
       "word_freq_will                   2492.370\n",
       "word_freq_people                  432.170\n",
       "word_freq_report                  269.740\n",
       "word_freq_addresses               226.390\n",
       "word_freq_free                   1144.950\n",
       "word_freq_business                656.040\n",
       "word_freq_email                   850.010\n",
       "word_freq_you                    7647.320\n",
       "word_freq_credit                  393.740\n",
       "word_freq_your                   3725.710\n",
       "word_freq_font                    557.650\n",
       "word_freq_000                     467.670\n",
       "word_freq_money                   433.730\n",
       "word_freq_hp                     2528.270\n",
       "word_freq_hpl                    1221.030\n",
       "word_freq_george                 3530.370\n",
       "word_freq_650                     574.410\n",
       "word_freq_lab                     455.110\n",
       "word_freq_labs                    473.220\n",
       "word_freq_telnet                  297.930\n",
       "word_freq_857                     216.470\n",
       "word_freq_data                    447.350\n",
       "word_freq_415                     220.090\n",
       "word_freq_85                      485.000\n",
       "word_freq_technology              448.490\n",
       "word_freq_1999                    630.120\n",
       "word_freq_parts                    60.740\n",
       "word_freq_pm                      361.770\n",
       "word_freq_direct                  298.300\n",
       "word_freq_cs                      200.910\n",
       "word_freq_meeting                 608.890\n",
       "word_freq_original                212.100\n",
       "word_freq_project                 364.380\n",
       "word_freq_re                     1385.930\n",
       "word_freq_edu                     827.370\n",
       "word_freq_table                    25.050\n",
       "word_freq_conference              146.630\n",
       "char_freq_;                       177.482\n",
       "char_freq_(                       639.679\n",
       "char_freq_[                        78.106\n",
       "char_freq_!                      1237.995\n",
       "char_freq_$                       348.805\n",
       "char_freq_hash                    203.540\n",
       "capital_run_length_average      23886.161\n",
       "capital_run_length_longest     240047.000\n",
       "capital_run_length_total      1303414.000\n",
       "spam                             1813.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no missing values in the Dataset\n",
    "email.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_freq_make                0\n",
       "word_freq_address             0\n",
       "word_freq_all                 0\n",
       "word_freq_3d                  0\n",
       "word_freq_our                 0\n",
       "word_freq_over                0\n",
       "word_freq_remove              0\n",
       "word_freq_internet            0\n",
       "word_freq_order               0\n",
       "word_freq_mail                0\n",
       "word_freq_receive             0\n",
       "word_freq_will                0\n",
       "word_freq_people              0\n",
       "word_freq_report              0\n",
       "word_freq_addresses           0\n",
       "word_freq_free                0\n",
       "word_freq_business            0\n",
       "word_freq_email               0\n",
       "word_freq_you                 0\n",
       "word_freq_credit              0\n",
       "word_freq_your                0\n",
       "word_freq_font                0\n",
       "word_freq_000                 0\n",
       "word_freq_money               0\n",
       "word_freq_hp                  0\n",
       "word_freq_hpl                 0\n",
       "word_freq_george              0\n",
       "word_freq_650                 0\n",
       "word_freq_lab                 0\n",
       "word_freq_labs                0\n",
       "word_freq_telnet              0\n",
       "word_freq_857                 0\n",
       "word_freq_data                0\n",
       "word_freq_415                 0\n",
       "word_freq_85                  0\n",
       "word_freq_technology          0\n",
       "word_freq_1999                0\n",
       "word_freq_parts               0\n",
       "word_freq_pm                  0\n",
       "word_freq_direct              0\n",
       "word_freq_cs                  0\n",
       "word_freq_meeting             0\n",
       "word_freq_original            0\n",
       "word_freq_project             0\n",
       "word_freq_re                  0\n",
       "word_freq_edu                 0\n",
       "word_freq_table               0\n",
       "word_freq_conference          0\n",
       "char_freq_;                   0\n",
       "char_freq_(                   0\n",
       "char_freq_[                   0\n",
       "char_freq_!                   0\n",
       "char_freq_$                   0\n",
       "char_freq_hash                0\n",
       "capital_run_length_average    0\n",
       "capital_run_length_longest    0\n",
       "capital_run_length_total      0\n",
       "spam                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are no missing values in the Dataset\n",
    "email.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4601.000000\n",
       "mean        0.394045\n",
       "std         0.488698\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email['spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of the spam\n",
    "round(email[\"spam\"].mean() * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  conduct some priliminary data preperation steps:\n",
    " * . rescaling the variables\n",
    " * . splitting into train and test \n",
    " * . print the summary status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_hash</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n",
       "count      4601.000000     4601.000000     ...       4601.000000  4601.000000   \n",
       "mean          0.090067        0.239413     ...          0.038575     0.139030   \n",
       "std           0.278616        0.644755     ...          0.243471     0.270355   \n",
       "min           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "25%           0.000000        0.000000     ...          0.000000     0.000000   \n",
       "50%           0.000000        0.000000     ...          0.000000     0.065000   \n",
       "75%           0.000000        0.160000     ...          0.000000     0.188000   \n",
       "max           5.260000       18.180000     ...          4.385000     9.752000   \n",
       "\n",
       "       char_freq_[  char_freq_!  char_freq_$  char_freq_hash  \\\n",
       "count  4601.000000  4601.000000  4601.000000     4601.000000   \n",
       "mean      0.016976     0.269071     0.075811        0.044238   \n",
       "std       0.109394     0.815672     0.245882        0.429342   \n",
       "min       0.000000     0.000000     0.000000        0.000000   \n",
       "25%       0.000000     0.000000     0.000000        0.000000   \n",
       "50%       0.000000     0.000000     0.000000        0.000000   \n",
       "75%       0.000000     0.315000     0.052000        0.000000   \n",
       "max       4.081000    32.478000     6.003000       19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total         spam  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email.describe()\n",
    "# observe capital_run_length_average column ,capital_run_length_longest,capital_run_length_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into X and Y\n",
    "x = email.drop('spam',axis =1) # feature variables are except spam remaining all are feature variables.\n",
    "# so delete the spam column from the data set assaigning to the X .\n",
    "y = email.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "# note that the scale function standardises each column\n",
    "# x = x-mean(x)/std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the scale\n",
    "from sklearn.preprocessing import scale\n",
    "x = scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splittining into train and test data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,train_size = 0.7 , test_size =0.3,random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38944099378881986"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean() # confirming that splitting also has similar distribution of spam and ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4047791455467053"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a linear SVM model now.\n",
    "# we highly recommend reading the documentation at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm.classes:\n",
      "\n",
      "class SVC(sklearn.svm.base.BaseSVC)\n",
      " |  SVC(C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`sklearn.linear_model.LinearSVC` or\n",
      " |  :class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  kernel : string, optional (default='rbf')\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |      a callable.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.var())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  probability : boolean, optional (default=False)\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, and will slow down that method.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : {dict, 'balanced'}, optional\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : 'ovo', 'ovr', default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      The seed of the pseudo random number generator used when shuffling\n",
      " |      the data for probability estimates. If int, random_state is the\n",
      " |      seed used by the random number generator; If RandomState instance,\n",
      " |      random_state is the random number generator; If None, the random\n",
      " |      number generator is the RandomState instance used by `np.random`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [n_SV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : array-like, dtype=int32, shape = [n_class]\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [n_class-1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the section about multi-class classification in the\n",
      " |      SVM section of the User Guide for details.\n",
      " |  \n",
      " |  coef_ : array, shape = [n_class * (n_class-1) / 2, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  probA_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |  probB_ : array, shape = [n_class * (n_class-1) / 2]\n",
      " |      If probability=True, the parameters learned in Platt scaling to\n",
      " |      produce probability estimates from decision values. If\n",
      " |      probability=False, an empty array. Platt scaling uses the logistic\n",
      " |      function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = SVC(gamma='auto')\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      " |      decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      " |      max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      " |      tol=0.001, verbose=False)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SVR\n",
      " |      Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC\n",
      " |      Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm.base.BaseSVC\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, C=1.0, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluates the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array-like, shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseSVC:\n",
      " |  \n",
      " |  predict_log_proba\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          [n_samples_test, n_samples_train]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help command is used to know how to use.\n",
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    " # model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancea an object of class SVC\n",
    "# note that we are using cost C = 1\n",
    "model = SVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit \n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model using confusion matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[782,  40],\n",
       "       [ 63, 496]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_true = y_test , y_pred = y_pred)\n",
    "# [ TN  FN]\n",
    "# [ FP  TP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is :  0.9254163649529327\n",
      "precision is : 0.9253731343283582\n",
      "recall is : 0.8872987477638641\n"
     ]
    }
   ],
   "source": [
    " # print the metrics\n",
    "print(\"accuracy is : \", metrics.accuracy_score(y_test,y_pred))\n",
    "# accuracy is correct_samples/ test_samples\n",
    "\n",
    "# precision\n",
    "\n",
    "print(\"precision is :\",metrics.precision_score(y_test,y_pred))\n",
    "\n",
    "# recall/sensitivity/True negativity rate\n",
    "print(\"recall is :\",metrics.recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity 0.9513381995133819\n"
     ]
    }
   ],
   "source": [
    "# print specificity (% of hams correctly classified) = TN / (TN+FN)\n",
    "print(\"specificity\",782/(782+40))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The SVM we have build so far gives decently good results.\n",
    "an accuracy of 92% \n",
    "sensitivity/recall(TPR) of 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERPRETATION OF RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the confusion matrix , the elements at (0,0) and(1,1)\n",
    "correspond to the more frequently occuring class  ,i.e: ham emails . thus ,it implies that:\n",
    "        * . 92%   of emails are classified correctly.\n",
    "        * . 88.5% of spams are identified correctly (recall = TPR = TP/(TP+FN)).\n",
    "        * . specificity  or % of hams classified is 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * ** hyper parameter tuning * ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics.classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification\n",
      "    \n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` but\n",
      "    predicted to be in group :math:`j`.\n",
      "    \n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array, shape = [n_samples]\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : array, shape = [n_samples]\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array, shape = [n_classes], optional\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If none is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : array, shape = [n_classes, n_classes]\n",
      "        Confusion matrix\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes)\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    In the binary case, we can extract true positives, etc as follows:\n",
      "    \n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first run a simple k-Fold cross validation to get a sense of the average metrics as computed over multiple folds.\n",
    "the easiest way to do cross-validation is to use the cross_val_score() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a KFold object with 5 splits\n",
    "folds = KFold(n_splits = 5,shuffle = True,random_state  = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# istantiating a model with cost =1\n",
    "model = SVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the cross-validation scores\n",
    "# note that the argument CV takes the \"folds\",object\n",
    "# we have specified 'accuracy' as the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_results = sklearn.model_selection.cross_val_score(model,x_train,y_train,cv = folds,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93012422 0.93012422 0.93944099 0.93478261 0.93167702]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results) # print 5 accuracies obtained from the 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332298136645963"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy =0.9332298136645963\n"
     ]
    }
   ],
   "source": [
    "print(\"mean accuracy ={}\".format(cv_results.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits = 5,shuffle = True,random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_val_score(model,x_train,y_train,cv = folds,scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93012422 0.93012422 0.93944099 0.93478261 0.93167702]\n"
     ]
    }
   ],
   "source": [
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9332298136645963"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * ** Grid Search to Find Optimal Hyperparameter C * **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold CV helps us compute average metrics over multiple folds , and that is the best indication of the \"test accuracy/othermetric score\" we can have\n",
    "\n",
    "But we want to use CV to compute the optimal values of hyperparameters .\n",
    "(in this case ,the cost C is a hyperparameter).\n",
    "\n",
    "this is done using the GridSearchCV() method,which computes metrics (such as accuracy,recall ...etc)\n",
    "\n",
    "in this case,we have only one hyperparameter,though you can have multiple,such as C and gamma in non-linear SVMs.\n",
    "\n",
    "in that case, you need to search through a grid of multiple values of C and gamma to find the optimal combination,and hence name GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify range of parameters (c) as a list\n",
    "params  = {\"c\":[0.1,1,10,100,1000]}\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Grid search scheme.\n",
    "# note that we are still using the 5 fold CV scheme we set up earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = GridSearchCV(estimator = model,param_grid = params,scoring = 'accuracy',cv = folds,verbose = 1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter c for estimator SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-53bfe8e27ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    222\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter c for estimator SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n    shrinking=True, tol=0.001, verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "model_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-7266b372ab22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "cv_results = pd .DataFrame(model_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93012422, 0.93012422, 0.93944099, 0.93478261, 0.93167702])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    " # to get a better results of how training and test accuracy varies with C\n",
    " #   let's plot the training and test accuracies against C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-384685011345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot of C versus train and test scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'param_c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of C versus train and test scores\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(cv_results['param_c'],cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_c'],cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.lezend(['test accuracy','train accuracy'],loc = 'upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the training accuracy monotonically increases with C, the test accuracy gradually reduces. Thus, we can conclude that higher values of C tend to overfit the model. This is because a high C value aims to classify all training examples correctly (since C is the cost of misclassification - if you impose a high cost on the model, it will avoid misclassifying any points by overfitting the data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally look at the optimal C values found by GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-5721b89dbb3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the highest test accuracy is {0} at c = {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "best_score = model_cv.best_score_\n",
    "best_c = model_cv.best_params_['C']\n",
    "print(\"the highest test accuracy is {0} at c = {1}\".format(best_score,best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-b76771c78546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model with the best value of c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_c' is not defined"
     ]
    }
   ],
   "source": [
    "# model with the best value of c\n",
    "model = SVC(C=best_c)\n",
    "# fit\n",
    "model.fit(x_train,y-train)\n",
    "#predict\n",
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.9254163649529327\n",
      "precision is :  0.9253731343283582\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-57bcc164a326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall is : \"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "# accuracy\n",
    "print(\"accuracy is :\" ,metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "# precision\n",
    "print(\"precision is : \",metrics.precision_score(y_test,y_pred))\n",
    "\n",
    "# recall\n",
    "print(\"recall is : \" ,metrics.recall_score(y-test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimising for Other Evaluation Metrics\n",
    "\n",
    "In this case, we had optimised (tuned) the model based on overall accuracy, though that may not always be the best metric to optimise. For example, if you are concerned more about catching all spams (positives), you may want to maximise TPR or sensitivity/recall. If, on the other hand, you want to avoid classifying hams as spams (so that any important mails don't get into the spam box), you would maximise the TNR or specificity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-3eed4c91c7f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tuning hyper-parameters for {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# set up grid search for score metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "# specify params\n",
    "params = {'c':[10,20,30,40,50]}\n",
    "\n",
    "# specify scores/metrics in an iterable\n",
    "\n",
    "scores = ['accuracy','precision','recall']\n",
    "\n",
    "for scores in scores:\n",
    "    print(\"tuning hyper-parameters for {}\".format(score))\n",
    "    # set up grid search for score metric\n",
    "    clf = GridSearchCV(SVC(),params,cv=folds,scoring = score,return_train_score=True)\n",
    "    \n",
    "    # fit\n",
    "    clf.fit(x_train,y_train)\n",
    "    \n",
    "    print('the highest {0} score is {1} at c = {2}'.format(score,clf.best))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Decision TREE ** *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case study, we will build a decision tree to predict the income of a given population, which is labelled as <=50𝐾𝑎𝑛𝑑>\n",
    "\n",
    "50K. The attributes (predictors) are age, working class type, marital status, gender, race etc.\n",
    "\n",
    "In the following sections, we'll:\n",
    "\n",
    "    clean and prepare the data,\n",
    "    build a decision tree with default hyperparameters,\n",
    "    understand all the hyperparameters that we can tune, and finally\n",
    "    choose the optimal hyperparameters using grid search cross-validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/19. Decision Tree/1.1 DT_forudemy.zip/DT_forudemy/adult_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education.num     32561 non-null int64\n",
      "marital.status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital.gain      32561 non-null int64\n",
      "capital.loss      32561 non-null int64\n",
      "hours.per.week    32561 non-null int64\n",
      "native.country    32561 non-null object\n",
      "income            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe that the columns workclass and occupation consist of missing values which are represented as '?' in the dataframe.\n",
    "\n",
    "On looking a bit more closely, you will also find that whenever workclass is having a missing value, occupation is also missing in that row. Let's check how may rows are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.workclass== '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51</td>\n",
       "      <td>?</td>\n",
       "      <td>172175</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2824</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>61</td>\n",
       "      <td>?</td>\n",
       "      <td>135285</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2603</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>71</td>\n",
       "      <td>?</td>\n",
       "      <td>100820</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2489</td>\n",
       "      <td>15</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0    90         ?   77053       HS-grad              9             Widowed   \n",
       "2    66         ?  186061  Some-college             10             Widowed   \n",
       "14   51         ?  172175     Doctorate             16       Never-married   \n",
       "24   61         ?  135285       HS-grad              9  Married-civ-spouse   \n",
       "44   71         ?  100820       HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "   occupation   relationship   race     sex  capital.gain  capital.loss  \\\n",
       "0           ?  Not-in-family  White  Female             0          4356   \n",
       "2           ?      Unmarried  Black  Female             0          4356   \n",
       "14          ?  Not-in-family  White    Male             0          2824   \n",
       "24          ?        Husband  White    Male             0          2603   \n",
       "44          ?        Husband  White    Male             0          2489   \n",
       "\n",
       "    hours.per.week native.country income  \n",
       "0               40  United-States  <=50K  \n",
       "2               40  United-States  <=50K  \n",
       "14              40  United-States   >50K  \n",
       "24              32  United-States  <=50K  \n",
       "44              15  United-States  <=50K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1836 entries, 0 to 32544\n",
      "Data columns (total 15 columns):\n",
      "age               1836 non-null int64\n",
      "workclass         1836 non-null object\n",
      "fnlwgt            1836 non-null int64\n",
      "education         1836 non-null object\n",
      "education.num     1836 non-null int64\n",
      "marital.status    1836 non-null object\n",
      "occupation        1836 non-null object\n",
      "relationship      1836 non-null object\n",
      "race              1836 non-null object\n",
      "sex               1836 non-null object\n",
      "capital.gain      1836 non-null int64\n",
      "capital.loss      1836 non-null int64\n",
      "hours.per.week    1836 non-null int64\n",
      "native.country    1836 non-null object\n",
      "income            1836 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 229.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensional Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"/home/ramchowdary/Desktop/[FreeTutorials.Eu] Udemy - Machine Learning A-Z  Become Kaggle Master/23. Dimension Reduction/1.1 PCA code for udemy.zip/PCA code for udemy/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = d1['label']  # save the labels into a variable l1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d1.drop(\"label\",axis=1) # drop the label feature and store the pixel data in d2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 251.2 MB\n"
     ]
    }
   ],
   "source": [
    "d2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape # 784 columns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "idx = 1\n",
    "grid_data = d2.iloc[idx].as_matrix().reshape(28,28)\n",
    "plt.imshow(grid_data,interpolation = \"none\",cmap = \"gray\")\n",
    "plt.show()\n",
    "print(l1[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramchowdary/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "idx = 1\n",
    "\n",
    "grid_data = d2.iloc[idx].as_matrix().reshape(28,28) # reshape from 1d to 2d pixel array.\n",
    "plt.imshow(grid_data,interpolation = \"none\",cmap = 'gray')\n",
    "plt.show()\n",
    "print(l1[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2D Visualization using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick first 15000 datapoints to work on for time-efficiency.\n",
    "labels = l1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d2.head(15000) # take 15k values and store in the variable = data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of simple data :  (15000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of simple data : \",data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data - preprocessing: Standardizing the data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = StandardScaler().fit_transform(data) # to standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 784)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the covariance matrix which is : A^T*A\n",
    "sample = sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication using numpy\n",
    "cov = np.matmul(sample.T , sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of variance matrix :  (784, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"the shape of variance matrix : \" ,cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the top2 eigen-values and corresponding eigen-vectors\n",
    "# for projecting onto a 2-dimensional space.\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the parameter 'eigvals' is defined(low value to high value)\n",
    "# eigh function will return the eigen values in ascending order.\n",
    "# this code generates only the top 2 eigen values (782 and 783)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "values , vectors = eigh(cov,eigvals=(782,783))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of eigen vectors =  (784, 2)\n"
     ]
    }
   ],
   "source": [
    "print('shape of eigen vectors = ',vectors.shape)\n",
    "# converting the eigen vectors into (2,d) shape for easyness of further computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update shape of eigen vectors =  (2, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"update shape of eigen vectors = \" ,vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the vectors[1] represent the eigen vector corresponding 1st principal eign vector.\n",
    "# formed the vectors[0] represents the eigen vector corresponding 2nd principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projecting the original data sample on the plane\n",
    "# formed by two principal eigen vectors by vector-vector multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coordinates = np.matmul(vectors,sample.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultant new data points shape : (2, 784) x (784, 15000)  =  (2, 15000)\n"
     ]
    }
   ],
   "source": [
    "print('resultant new data points shape :',vectors.shape,'x',sample.T.shape,\" = \", new_coordinates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.5586608 ,  6.19363477, -1.90987794, ..., -2.14793723,\n",
       "         3.20412249, -6.87896871],\n",
       "       [-5.04355835, 19.30527806, -7.67877525, ..., -1.50726893,\n",
       "        -6.53731291, -1.25625388]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-7c4e2b257741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# appending label to the 2d projected data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# appending label to the 2d projected data\n",
    "new = np.vstack(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-1074339d538c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "new_coordinates = np.vstack((new_coordinates, labels)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
